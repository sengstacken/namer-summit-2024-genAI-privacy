{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9691ea2b-3ee8-4742-9ff1-ca933e1bc72d",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock\n",
    "## Access Control Filtering - End to end notebook\n",
    "\n",
    "This notebook will guide the users on creating access controls for Knowledge Bases on Amazon Bedrock.\n",
    "\n",
    "To demonstrate the access control capabilities enabled by metadata filtering in Knowledge Bases, let's consider a use case where you work at a large enterprise, AcmeCorp. At AcmeCorp we want to create a Knowledge Base containing content from various s3 buckets.  However, each user does not have access to all data. A RAG architecture is perfect for this use case since we can restrict the retrieval to only the documents we have access to.  \n",
    "\n",
    "To complete this notebook you should have a role with access to the following services: Amazon S3, AWS STS, AWS Lambda, AWS CloudFormation, Amazon Bedrock, Amazon Cognito and Amazon Opensearch Serverless. \n",
    "\n",
    "This notebook contains the following sections:\n",
    "\n",
    "0. **Base Infrastructure Deployment**: In this section you will deploy an Amazon Cloudformation Template which will create and configure some of the services used for the solution. \n",
    "1. **Amazon Cognito:** You are going to populate an Amazon Cognito pool with three users. We will use the unique identifiers generated by Cognito for each user to associate document corpus with the respective users.\n",
    "2. **User-corpus association in Amazon DynamoDB:** You will populate an Amazon DynamoDB table which will store user-corpus associations. \n",
    "3. **Dataset download:** For this notebook you will use documents provided in an s3 bucket and stored in 3 different folders.\n",
    "4. **Metadata association:** You will use the user identifiers generated by Cognito to create metadata files associated to each corpus.\n",
    "5. **Create OpensearchServerless** You will create an OpenSearch Serverless collection to be used by Amazon Knowledge Base.\n",
    "6. **Create a Knowledge Base for Amazon Bedrock**: You will create and sync the Knowledge Base with the documents and associated metadata.\n",
    "7. **Update AWS Lambda:** Until Boto3/Lambda is updated -- Create a Lambda Layer to include the latest SDK.\n",
    "8. **Create and run a Streamlit Application:** You will create a simple interface to showcase access control with metadata filtering using a Streamlit application\n",
    "9. **Clean up:** Delete all the resources created during this notebook to avoid unnecessary costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e51edb0-cae2-4929-b0a5-8a8057c7f467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.34.4 requires botocore==1.35.4, but you have botocore 1.35.13 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU opensearch-py streamlit streamlit-cognito-auth retrying boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c10f35-09a3-4e9c-8f73-e9235609ac0b",
   "metadata": {},
   "source": [
    "Let's import necessary Python modules and libraries, and initialize AWS service clients required for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3502ca-2256-499d-9d37-70021e379a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import requests\n",
    "import random\n",
    "from utilsmod import create_base_infrastructure, create_kb_infrastructure, updateDataAccessPolicy, createAOSSIndex, replace_vars\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "lambda_client = boto3.client('lambda')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "cloudformation = boto3.client('cloudformation')\n",
    "opensearch = boto3.client('opensearchserverless')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock = boto3.client(\"bedrock\",region_name=region)\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "cognito_client = boto3.client('cognito-idp', region_name=region)\n",
    "identity_arn = session.client('sts').get_caller_identity()['Arn']\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "bucket_name = 'namer-' + account_id + '-bucket'\n",
    "user_pool_id = cognito_client.list_user_pools(MaxResults=1)[\"UserPools\"][0][\"Id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee423c-bc86-401c-8bb4-affd884ccfe0",
   "metadata": {},
   "source": [
    "### 0. Base Infrastructure \n",
    "The following has already been created for you by the workshop: \n",
    "\n",
    "- Amazon Cognito User Pool and App Client. (user_pool_id, cognito_arn, client_id, client_secret)\n",
    "- Amazon DynamoDB Table\n",
    "- Amazon S3 Bucket\n",
    "- AWS Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d45776-1ded-4ff3-ad9a-5a7d34610a85",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f6f55-689a-4aae-b3c3-e29883998359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "def short_uuid():\n",
    "    uuid_str = str(uuid.uuid4())\n",
    "    return uuid_str[:8]\n",
    "\n",
    "solution_id = 'KBS{}'.format(short_uuid()).lower()\n",
    "user_pool_id, user_pool_arn, cognito_arn, client_id, client_secret, dynamo_table, s3_bucket, lambda_function_arn, collection_id = create_base_infrastructure(solution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785975c8-dffe-4a3b-b113-50d795e5862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "%store user_pool_id user_pool_arn cognito_arn client_id client_secret dynamo_table s3_bucket lambda_function_arn collection_id solution_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e64b05-9bfb-43e2-8d62-551a7ffb62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40293544-d50a-4bb9-8a4f-e7700590200e",
   "metadata": {},
   "source": [
    "### 1. Amazon Cognito User Pool: Users and Corpus\n",
    "#### Create users and corpus into the user pool\n",
    "We will create users and corpus to test out the use case. User ids are stored for later use when retrieving information.\n",
    "For the notebook to work you will need to replace the placeholder for 2 doctors and 3 patients. This users will be created in the Amazon Cognito user pool and you will later need them to log into the web application. While this is a dummy user creation for test purposes, in production use cases you will need to follow you organization best practices and guidelines to create users. \n",
    "\n",
    "**For this example, the first doctor will have associated the first two patients, and the second doctor will have associated the third patient.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc1b6e-1b68-49c8-b111-be43ac493294",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> \n",
    "<br><b>Password minimum length:</b>8 character(s)\n",
    "<br><b>Password requirements</b>\n",
    "<br>Contains at least 1 number\n",
    "<br>Contains at least 1 special character\n",
    "<br>Contains at least 1 uppercase letter\n",
    "<br>Contains at least 1 lowercase letter\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0a7b1dc-08a2-4d89-972f-dddb1a3d0439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "users = [\n",
    "    {\n",
    "        'name': 'Highway Harry',\n",
    "        'email': 'highway.harry@acmecorp.com',\n",
    "        'password': 'Highway.Harry.123$',\n",
    "        'corpus': ['highway']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wildlife Walter',\n",
    "        'email': 'wildlife.walter@acmecorp.com',\n",
    "        'password': 'Wildlife.Walter.123$',\n",
    "        'corpus': ['wildlife']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Admin Amy',\n",
    "        'email': 'admin.amy@acmecorp.com',\n",
    "        'password': 'Admin.Amy.123$',\n",
    "        'corpus': ['highway', 'wildlife']\n",
    "    },\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    {\n",
    "        'name': 'highway',\n",
    "        'description': 'document regarding highway and roadsign regulations',\n",
    "        's3path': f's3://{0}/highway/'.format(bucket_name)\n",
    "    },\n",
    "    {\n",
    "        'name': 'wildlife',\n",
    "        'description': 'documents regarding fishing and hunting regulations',\n",
    "        's3path': f's3://{0}/wildlife/'.format(bucket_name)\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2131a29e-c8b0-4446-b00f-638f90b8ab98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User created: highway.harry@acmecorp.com\n",
      "User id: 04c8a448-8031-7098-187b-e5f14600ed8c\n",
      "User created: wildlife.walter@acmecorp.com\n",
      "User id: f478f458-20e1-70bd-32b3-5be5ef63662d\n",
      "User created: admin.amy@acmecorp.com\n",
      "User id: f4282408-1011-70cf-55c3-80d4d8bb5acd\n",
      "User IDs: ['04c8a448-8031-7098-187b-e5f14600ed8c', 'f478f458-20e1-70bd-32b3-5be5ef63662d', 'f4282408-1011-70cf-55c3-80d4d8bb5acd']\n",
      "Corpus IDs: ['32d3518f-708f-460c-b490-e26a5f9f80b5', 'ea277a43-fa77-42de-bf36-fe3a92f31dea']\n",
      "Stored 'user_ids' (list)\n",
      "Stored 'corpus_ids' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_ids = []\n",
    "corpus_ids = []\n",
    "\n",
    "def create_user(user_data, user_type):\n",
    "    user_ids = []\n",
    "    for user in user_data:\n",
    "        response = cognito_client.admin_create_user(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            UserAttributes=[\n",
    "                {'Name': 'name', 'Value': user['name']},\n",
    "                {'Name': 'email', 'Value': user['email']},\n",
    "                {'Name': 'email_verified', 'Value': 'true'}\n",
    "            ],\n",
    "            ForceAliasCreation=False,\n",
    "            MessageAction='SUPPRESS'\n",
    "        )\n",
    "        cognito_client.admin_set_user_password(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            Password=user['password'],\n",
    "            Permanent=True\n",
    "        )\n",
    "        print(f\"{user_type.capitalize()} created:\", response['User']['Username'])\n",
    "        print(f\"{user_type.capitalize()} id:\", response['User']['Attributes'][3]['Value'])\n",
    "        user_ids.append(response['User']['Attributes'][3]['Value'])\n",
    "    return user_ids\n",
    "\n",
    "user_ids = create_user(users, 'user')\n",
    "corpus_ids = [str(uuid.uuid4()) for c in corpus]\n",
    "\n",
    "print(\"User IDs:\", user_ids)\n",
    "print(\"Corpus IDs:\", corpus_ids)\n",
    "\n",
    "%store user_ids corpus_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293facc-39be-46eb-a7e9-696a1084c679",
   "metadata": {},
   "source": [
    "### 2. User-corpus association in DynamoDB\n",
    "In this section we will populate the already created DynamoDB table with the user-corpus associations. This will be useful later on to retrieve the list of corpus ids a user is allowed to filter by. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15faadd4-960f-47ed-8793-b65fc2a65e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "table = dynamodb_resource.Table('namer-{0}-User_corpus_list_association'.format(account_id))\n",
    "corpus_mapping = [entry['name'] for entry in corpus]\n",
    "with table.batch_writer() as batch:\n",
    "    for corpus_list,user in enumerate(users):\n",
    "        temp = []\n",
    "        for corpus_id,corpuses in enumerate(corpus_mapping):\n",
    "            if corpuses in user['corpus']:\n",
    "                temp.append(corpus_ids[corpus_id])\n",
    "\n",
    "        batch.put_item(\n",
    "            Item={\n",
    "                'user_id': user_ids[corpus_list],\n",
    "                'corpus_id_list': temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "print('Data inserted successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda19f76-ae71-4862-9f79-b1a5d7b2a2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/namer-summit-2024-genAI-privacy/source_transcripts/wildlife/Loon - Wikipedia.pdf uploaded successfully to namer-850754977538-bucket with key wildlife/Loon - Wikipedia.pdf.\n",
      "/home/ec2-user/SageMaker/namer-summit-2024-genAI-privacy/source_transcripts/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf uploaded successfully to namer-850754977538-bucket with key wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf.\n",
      "/home/ec2-user/SageMaker/namer-summit-2024-genAI-privacy/source_transcripts/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf uploaded successfully to namer-850754977538-bucket with key highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf.\n"
     ]
    }
   ],
   "source": [
    "abs_path = os.path.abspath(\"source_transcripts\")\n",
    "\n",
    "for root, dirs, files in os.walk(abs_path):\n",
    "    for file_name in files:\n",
    "        # Construct the full local path to the file\n",
    "        local_file_path = os.path.join(root, file_name)\n",
    "        \n",
    "        # Construct the S3 key (object key) using the relative path of the file\n",
    "        s3_key = os.path.relpath(local_file_path, abs_path)\n",
    "        \n",
    "        # Upload the file to S3\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_key)\n",
    "        \n",
    "        print(f'{local_file_path} uploaded successfully to {bucket_name} with key {s3_key}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8a8769a-b265-4cb9-bdb3-599ff4be305a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namer-850754977538-bucket\n"
     ]
    }
   ],
   "source": [
    "# Loop through the corpus and their corresponding IDs\n",
    "print(bucket_name)\n",
    "for corpuses, corpus_entry in enumerate(corpus):\n",
    "    corpus_id = corpus_ids[corpuses]\n",
    "    s3path = corpus_entry['s3path']\n",
    "    \n",
    "    # Get bucket and prefix\n",
    "    # Remove 's3://' and split bucket and prefix\n",
    "    path_parts = s3path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    prefix = path_parts[1] if len(path_parts) > 1 else ''\n",
    "    \n",
    "    # List all files in the S3 folder\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        files = [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    else:\n",
    "        files = []\n",
    "    \n",
    "    for file in files:\n",
    "        metadata = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"corpus_id\": corpus_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload metadata file to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=f\"{file}.metadata.json\",\n",
    "            Body=json.dumps(metadata, indent=4),\n",
    "            ContentType='application/json'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0474937-035d-4900-a877-dca3c674b45e",
   "metadata": {},
   "source": [
    "### 5. Upload to Amazon S3\n",
    "Knowledge Bases for Amazon Bedrock, currently require data to reside in an Amazon S3 bucket. We will upload both files and metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700ad37-73b8-4200-a7da-efe66ae02f1f",
   "metadata": {},
   "source": [
    "### 6. Create OpensearchServerless\n",
    "\n",
    "In this section we will create all the policies for the OpenSearch Serverless Collection and then create the collection itself.\n",
    "\n",
    "First we will create an encryption policy for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "489ef438-e4da-4657-a1e3-8a4de72b36ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Rules\":[{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-850754977538-kbcollection\"]}], \"AWSOwnedKey\": true}\n",
      "{'securityPolicyDetail': {'createdDate': 1725574356609, 'description': 'Public encryption access namer workshop collection', 'lastModifiedDate': 1725574356609, 'name': 'namer-850754977538-kbenc', 'policy': {'Rules': [{'Resource': ['collection/namer-850754977538-kbcollection'], 'ResourceType': 'collection'}], 'AWSOwnedKey': True}, 'policyVersion': 'MTcyNTU3NDM1NjYwOV8x', 'type': 'encryption'}, 'ResponseMetadata': {'RequestId': '3ccc018b-95a6-4ab2-9def-ea0535349870', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3ccc018b-95a6-4ab2-9def-ea0535349870', 'date': 'Thu, 05 Sep 2024 22:12:36 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '375', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '{{\"Rules\":[{{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-{0}-kbcollection\"]}}], \"AWSOwnedKey\": true}}'.format(account_id)\n",
    "print(policy)\n",
    "\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public encryption access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbenc',\n",
    "    policy=policy,\n",
    "    type='encryption'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89f434-c101-4495-8975-95873957d7a9",
   "metadata": {},
   "source": [
    "Now we will create a Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09cf22ad-37ef-4c0f-ac9c-5a2f8070022f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Rules\": [{\"ResourceType\": \"dashboard\", \n",
      "    \"Resource\": [\"collection/namer-850754977538-kbcollection\"]}, \n",
      "    {\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer850754977538-kbcollection\"]}], \n",
      "    \"AllowFromPublic\": true}]\n",
      "{'securityPolicyDetail': {'createdDate': 1725574359834, 'description': 'Public network access namer workshop collection', 'lastModifiedDate': 1725574359834, 'name': 'namer-850754977538-kbnet', 'policy': [{'Rules': [{'Resource': ['collection/namer-850754977538-kbcollection'], 'ResourceType': 'dashboard'}, {'Resource': ['collection/namer850754977538-kbcollection'], 'ResourceType': 'collection'}], 'AllowFromPublic': True}], 'policyVersion': 'MTcyNTU3NDM1OTgzNF8x', 'type': 'network'}, 'ResponseMetadata': {'RequestId': '790c66d3-3bd3-4463-bae7-816e78238fe2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '790c66d3-3bd3-4463-bae7-816e78238fe2', 'date': 'Thu, 05 Sep 2024 22:12:39 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '461', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '''[{{\"Rules\": [{{\"ResourceType\": \"dashboard\", \n",
    "    \"Resource\": [\"collection/namer-{0}-kbcollection\"]}}, \n",
    "    {{\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer{0}-kbcollection\"]}}], \n",
    "    \"AllowFromPublic\": true}}]'''.format(account_id)\n",
    "print(policy)\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public network access namer workshop collection',\n",
    "    name='namer-{0}-kbnet'.format(account_id),\n",
    "    policy=policy,\n",
    "    type='network'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d0935-28c4-4013-9a58-434a68abd5ca",
   "metadata": {},
   "source": [
    "Next we need to create the Data Access Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09a89b4c-61c3-4ef3-9ac1-de2ccd43d6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Rules\": [{\"Resource\": [\"collection/namer-850754977538-kbcollection\"], \n",
      "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
      "                           \"ResourceType\": \"collection\"}, \n",
      "                          {\"ResourceType\": \"index\", \"Resource\": [\"index/namer-850754977538-kbcollection/*\"], \n",
      "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}], \n",
      "                \"Principal\": [\"arn:aws:iam::850754977538:role/namer-850754977538-kbrole\"]}]\n"
     ]
    }
   ],
   "source": [
    "policy = '''[{{\"Rules\": [{{\"Resource\": [\"collection/namer-{0}-kbcollection\"], \n",
    "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
    "                           \"ResourceType\": \"collection\"}}, \n",
    "                          {{\"ResourceType\": \"index\", \"Resource\": [\"index/namer-{0}-kbcollection/*\"], \n",
    "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}}], \n",
    "                \"Principal\": [\"arn:aws:iam::{0}:role/namer-{0}-kbrole\"]}}]'''.format(account_id)\n",
    "print(policy)\n",
    "results = opensearch.create_access_policy(\n",
    "    description='Data access policy for the NAMER summit',\n",
    "    name='namer-{0}-kbaccess'.format(account_id),\n",
    "    policy=policy,\n",
    "    type='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66443aa1-802a-406c-b58d-9bbb4c2cf4c9",
   "metadata": {},
   "source": [
    "Now that we have our policies we can create the OpenSearch Serverless Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fb4e8f0-2b25-4de2-b947-1ced00c3a0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createCollectionDetail': {'arn': 'arn:aws:aoss:us-east-1:850754977538:collection/t2j02pxlpep84z5r7mfg', 'createdDate': 1725574368055, 'description': 'KB AOSS Collection', 'id': 't2j02pxlpep84z5r7mfg', 'kmsKeyArn': 'auto', 'lastModifiedDate': 1725574368055, 'name': 'namer-850754977538-kbcollection', 'standbyReplicas': 'ENABLED', 'status': 'CREATING', 'type': 'VECTORSEARCH'}, 'ResponseMetadata': {'RequestId': '71a1b135-05de-41c7-ba01-980796001981', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '71a1b135-05de-41c7-ba01-980796001981', 'date': 'Thu, 05 Sep 2024 22:12:49 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '358', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "results = opensearch.create_collection(\n",
    "    description='KB AOSS Collection',\n",
    "    name='namer-{0}-kbcollection'.format(account_id),\n",
    "    type='VECTORSEARCH'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f7a64-933f-4e80-a722-98c0680e5bae",
   "metadata": {},
   "source": [
    "Creating the collection takes some time so we will check to see if it has been created yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c342988-f55c-4628-a0f1-e73cc9ed82f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created\n"
     ]
    }
   ],
   "source": [
    "response = opensearch.list_collections(collectionFilters={'name':'namer-{0}-kbcollection'.format(account_id)})\n",
    "collection_id = response[\"collectionSummaries\"][0][\"id\"]\n",
    "collection_arn = response[\"collectionSummaries\"][0][\"arn\"]\n",
    "while response[\"collectionSummaries\"][0][\"status\"] != \"ACTIVE\":\n",
    "    time.sleep(10)\n",
    "\n",
    "print(\"Collection created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72a007-409f-4c32-be0c-1e73bf868d4b",
   "metadata": {},
   "source": [
    "### 7. Create a Knowledge Base for Amazon Bedrock\n",
    "\n",
    "In this section we will go through all the steps to create and test a Knowledge Base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37b62c6a-08e1-48c1-9432-e230d0df30ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index name: namer-850754977538-kb-acl-index\n",
      "Stored 'indexName' (str)\n"
     ]
    }
   ],
   "source": [
    "indexName = \"namer-{0}-kb-acl-index\".format(account_id)\n",
    "print(\"Index name:\",indexName)\n",
    "%store indexName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a583a886-dbdd-4edd-abd9-246ebcda02cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessPolicyDetail': {'createdDate': 1725574364749, 'description': 'dataAccessPolicy', 'lastModifiedDate': 1725576036370, 'name': 'namer-850754977538-kbaccess', 'policy': [{'Rules': [{'Resource': ['collection/namer-850754977538-kbcollection'], 'Permission': ['aoss:CreateCollectionItems', 'aoss:UpdateCollectionItems', 'aoss:DescribeCollectionItems'], 'ResourceType': 'collection'}, {'Resource': ['index/namer-850754977538-kbcollection/*'], 'Permission': ['aoss:CreateIndex', 'aoss:DescribeIndex', 'aoss:ReadDocument', 'aoss:WriteDocument', 'aoss:UpdateIndex', 'aoss:DeleteIndex'], 'ResourceType': 'index'}], 'Principal': ['arn:aws:iam::850754977538:role/namer-850754977538-kbrole', 'arn:aws:iam::850754977538:role/us-east-1-850754977538-SageMaker-Execution-Namer-2024-Role/SageMaker']}], 'policyVersion': 'MTcyNTU3NjAzNjM3MF84', 'type': 'data'}, 'ResponseMetadata': {'RequestId': '004d5fe6-a67e-4633-bf3b-c9dcafd361f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '004d5fe6-a67e-4633-bf3b-c9dcafd361f1', 'date': 'Thu, 05 Sep 2024 22:40:36 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '812', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "Finished adding the role\n"
     ]
    }
   ],
   "source": [
    "# Adding the current role to the collection's data access policy\n",
    "data_access_policy_name = 'namer-{0}-kbaccess'.format(account_id)\n",
    "\n",
    "response = opensearch.get_access_policy(\n",
    "    name=data_access_policy_name,\n",
    "    type='data'\n",
    ")\n",
    "policy_version = response[\"accessPolicyDetail\"][\"policyVersion\"]\n",
    "existing_policy = response['accessPolicyDetail']['policy']\n",
    "updated_policy = existing_policy.copy()\n",
    "updated_policy[0]['Principal'].append('arn:aws:iam::{0}:role/{1}-{0}-SageMaker-Execution-Namer-2024-Role/SageMaker'.format(account_id, boto3.session.Session().region_name))\n",
    "updated_policy = str(updated_policy).replace(\"'\", '\"')\n",
    "\n",
    "response = opensearch.update_access_policy(\n",
    "    description='dataAccessPolicy',\n",
    "    name=data_access_policy_name,\n",
    "    policy=updated_policy,\n",
    "    policyVersion=policy_version,\n",
    "    type='data'\n",
    ")\n",
    "print(response)\n",
    "\n",
    "time.sleep(60) # Changes to the data access policy might take a bit to update\n",
    "print(\"Finished adding the role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbd0b5e4-1e5c-4659-9192-5fe4dbc844f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<botocore.credentials.RefreshableCredentials object at 0x7f204810f970>\n",
      "t2j02pxlpep84z5r7mfg.us-east-1.aoss.amazonaws.com\n"
     ]
    },
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException(401, '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 50\u001b[0m\n\u001b[1;32m     40\u001b[0m oss_client \u001b[38;5;241m=\u001b[39m OpenSearch(\n\u001b[1;32m     41\u001b[0m     hosts\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m'\u001b[39m: host, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m443\u001b[39m}],\n\u001b[1;32m     42\u001b[0m     http_auth\u001b[38;5;241m=\u001b[39mawsauth,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Create index\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43moss_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_settings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/client/utils.py:176\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m             params[p] \u001b[38;5;241m=\u001b[39m _escape(v)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/client/indices.py:236\u001b[0m, in \u001b[0;36mIndicesClient.create\u001b[0;34m(self, index, body, params, headers)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m SKIP_IN_PATH:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty value passed for a required argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPUT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_make_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/transport.py:455\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# connection didn't fail, confirm its live status\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_pool\u001b[38;5;241m.\u001b[39mmark_live(connection)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/transport.py:416\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    413\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_connection()\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     status, headers_response, data \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     headers_response \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    428\u001b[0m         header\u001b[38;5;241m.\u001b[39mlower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    429\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/http_requests.py:238\u001b[0m, in \u001b[0;36mRequestsHttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, allow_redirects, ignore, headers)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore\n\u001b[1;32m    228\u001b[0m ):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_fail(\n\u001b[1;32m    230\u001b[0m         method,\n\u001b[1;32m    231\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m         raw_data,\n\u001b[1;32m    237\u001b[0m     )\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_success(\n\u001b[1;32m    245\u001b[0m     method,\n\u001b[1;32m    246\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     duration,\n\u001b[1;32m    252\u001b[0m )\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mheaders, raw_data\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py:315\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[0;34m(self, status_code, raw_data, content_type)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    313\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, err)\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(status_code, TransportError)(\n\u001b[1;32m    316\u001b[0m     status_code, error_message, additional_info\n\u001b[1;32m    317\u001b[0m )\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException(401, '')"
     ]
    }
   ],
   "source": [
    "# Set up AWS authentication\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "print(credentials)\n",
    "awsauth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "# Define index settings and mappings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": \"true\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                 \"method\": {\n",
    "                     \"name\": \"hnsw\",\n",
    "                     \"engine\": \"faiss\",\n",
    "                     \"space_type\": \"innerproduct\",\n",
    "                     \"parameters\": {\n",
    "                         \"ef_construction\": 512,\n",
    "                         \"m\": 16\n",
    "                     },\n",
    "                 },\n",
    "             },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"text-metadata\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build the OpenSearch client\n",
    "host = f\"{collection_id}.{region}.aoss.amazonaws.com\"\n",
    "print(host)\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Create index\n",
    "response = oss_client.indices.create(index=indexName, body=json.dumps(index_settings))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e004121-cec0-4f79-a873-c5716d2eeea5",
   "metadata": {},
   "source": [
    "#### Create the Knowledge Base\n",
    "In this section you will create the Knowledge Base. Before creating a new KB we need to define which embeddings model we want it to use. In this case we will be using Amazon Titan Embeddings V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b7170-055f-4f34-be59-2f153f1f74c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Amazon Titan Embeddings V2 access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470be25-3c79-4eb0-b3bf-c419c1878a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModelArn = \"arn:aws:bedrock:{}::foundation-model/amazon.titan-embed-text-v2:0\".format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5d386-bd9b-4d0e-b660-4fb347ad07fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create our Knowledge Base for Amazon Bedrock. We have created an Amazon CloudFormation template which takes care of the configuration needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b087b-b5b1-4024-9149-b4026dd74450",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951db5fd-d6ca-48f8-8803-4cbd3b50bf2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#kb_id, datasource_id = create_kb_infrastructure(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)\n",
    "\n",
    "results = bedrock_agent_client.create_knowledge_base(\n",
    "    description='Test KB Deployment',\n",
    "    knowledgeBaseConfiguration={\n",
    "        'type': 'VECTOR',\n",
    "        'vectorKnowledgeBaseConfiguration': {\n",
    "            'embeddingModelArn': embeddingModelArn\n",
    "        }\n",
    "    },\n",
    "    name='namer-{0}-knowledge-base'.format(account_id),\n",
    "    roleArn='arn:aws:iam::{0}:role/Namer-{0}-SageMaker-Execution-KBRole'.format(account_id),\n",
    "    storageConfiguration={\n",
    "        'opensearchServerlessConfiguration': {\n",
    "            'collectionArn': collection_arn,\n",
    "            'fieldMapping': {\n",
    "                'metadataField': 'text-metadata',\n",
    "                'textField': 'text',\n",
    "                'vectorField': 'vector'\n",
    "            },\n",
    "            'vectorIndexName': indexName\n",
    "        },\n",
    "        'type': 'OPENSEARCH_SERVERLESS'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "kb_id = results[\"knowledgeBase\"][\"knowledgeBaseId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2accfd-0140-4102-a456-e93b2a27bc55",
   "metadata": {},
   "source": [
    "more instructions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961dae2-75b8-4814-a1b9-0f1937834f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bedrock_agent_client.create_data_source(\n",
    "    dataSourceConfiguration={\n",
    "        's3Configuration': {\n",
    "            'bucketArn': 'arn:aws:s3:::{0}'.format(bucket_name),\n",
    "        },\n",
    "        'type': 'S3',\n",
    "    },\n",
    "    description='KB Data Source',\n",
    "    knowledgeBaseId=kb_id,\n",
    "    name='namer-{0}-kb_datasource'.format(account_id),\n",
    "\n",
    "    vectorIngestionConfiguration={\n",
    "        'chunkingConfiguration': {\n",
    "            'chunkingStrategy': 'FIXED_SIZE',\n",
    "            'fixedSizeChunkingConfiguration': {\n",
    "                'maxTokens': 300,\n",
    "                'overlapPercentage': 20\n",
    "            },\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "datasource_id = results[\"dataSource\"][\"dataSourceId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3b55c-2b32-4375-9959-9ff502240620",
   "metadata": {},
   "source": [
    "#### Sync the Knowledge Base\n",
    "As we have created and associated the data source to the Knowledge Base, we can proceed to Sync the data. \n",
    "\n",
    "\n",
    "Each time you add, modify, or remove files from the S3 bucket for a data source, you must sync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon Bedrock only processes the objects in your S3 bucket that have been added, modified, or deleted since the last sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9c800-6e86-4fee-b09a-b8f4777d7fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingestion_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id,\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial Ingestion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e2bbf-6a21-4cfd-95e4-2102fdcb3b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "    dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "    ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    ")[\"ingestionJob\"][\"status\"]\n",
    "print(status)\n",
    "while status not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "    status = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "        dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "        ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    "    )[\"ingestionJob\"][\"status\"]\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "print(\"Waiting for changes to take place in the vector database\")\n",
    "time.sleep(30) # Wait for all changes to take place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b18f36-41ec-4083-a4f9-a08fc5ed3144",
   "metadata": {},
   "source": [
    "#### Test the Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the **retrieve** and **retrieve_and_generate** APIs.\n",
    "\n",
    "Let's examine a test case with patient 0's transcript, where they mention a cat named Kelly. We'll query the knowledge base using the metadata filter for patient 0 to retrieve information about Kelly. Changing the patient_id will prevent the model from responding accurately. Read through the PDFs for other questions you might want to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30d7f7-77e7-4745-a10f-3956d7f02b2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this first example we are going to use the **retrieve and generate API**. This API queries a knowledge base and generates responses based on the retrieved results, using an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b971c-e879-4d81-81c1-365f052523f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Anthropic Claude 3 Sonnet access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452bb02-651f-4d3f-8480-6eddb4b7f898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve and generate API\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"Which office do I submit for golden eagle permits?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\".format(region),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5,\n",
    "                    \"filter\": {\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"corpus_id\",\n",
    "                            \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2f8dd-aae4-4461-aa65-0f82cc74abc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this second example we are going to use the **retrieve API**. This API queries the knowledge base and retrieves relavant information from it, it does not generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb520b34-f6c9-4caa-bd00-3c8d65c9745a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":3,\n",
    "            \"filter\": {\n",
    "                 \"equals\": {\n",
    "                    \"key\": \"corpus_id\",\n",
    "                    \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "    retrievalQuery={\n",
    "        'text': \"Which office do I submit for golden eagle permits?\"   \n",
    "        }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents\n",
    "# each list has content,location,score,metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad65e10-3bad-4ca9-8009-8f85ed91f92e",
   "metadata": {},
   "source": [
    "### 7. Add Lambda Layer\n",
    "At the time of developing this notebook, the latest Boto3 version available in Lambda with Python 3.12 does not include metadata filtering capabilities. To solve this, we will create and attach an AWS Lambda Layer with the latest Boto3 version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428607b-0a0d-4efa-8bdd-dd29c63abc9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this section to run you will need the **zip** package to by installed at the system level.\n",
    "\n",
    "You can check if zip is installed running the following command: !zip\n",
    "\n",
    "If it is not installed you will need to install it using the appropriate package manager (apt-get for Debian-based systems or yum for RHEL-based systems for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c3644-09c3-4b11-aac9-2732204572f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we have the lambda layer already attached to the lambda function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68603d37-7e37-41c4-aa37-6997f680111f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!zip\n",
    "!sudo apt-get install zip -y # Debian-based systems \n",
    "#!sudo yum install zip -y # RHEL-based systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2126d9-7fe1-421c-879e-447ca4a1915d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir latest-sdk-layer\n",
    "%cd latest-sdk-layer\n",
    "!pip install -qU boto3 botocore -t python/lib/python3.12/site-packages/\n",
    "!zip -rq latest-sdk-layer.zip .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4894d13-7b90-40fc-96d2-de517574ff49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes):\n",
    "    with open(zip_file_path, 'rb') as f:\n",
    "        response = lambda_client.publish_layer_version(\n",
    "            LayerName=layer_name,\n",
    "            Description=description,\n",
    "            Content={\n",
    "                'ZipFile': f.read(),\n",
    "            },\n",
    "            CompatibleRuntimes=compatible_runtimes\n",
    "        )\n",
    "    return response['LayerVersionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171637fa-5671-44a3-be06-1f3400ec8fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_name = 'latest-sdk-layer'\n",
    "description = 'Layer with the latest boto3 version.'\n",
    "zip_file_path = 'latest-sdk-layer/latest-sdk-layer.zip'\n",
    "compatible_runtimes = ['python3.12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2e5c7-a29a-4d20-bd49-c6df4b605a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_version_arn = publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes)\n",
    "print(\"Layer version ARN:\", layer_version_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea5300-419a-4641-b4e8-453f434220a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Add the layer to the Lambda function\n",
    "    lambda_client.update_function_configuration(\n",
    "        FunctionName=lambda_function_arn,\n",
    "        Layers=[layer_version_arn]\n",
    "    )\n",
    "    print(\"Layer added to the Lambda function successfully.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    print(f\"Error adding layer to Lambda function: {e.response['Error']['Message']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5760a-f8e6-4ec6-852a-273afa467dfe",
   "metadata": {},
   "source": [
    "### 8. Create Streamlit Application\n",
    "To showcase the interaction between doctors and the Knowledge Bases, we can develop a user-friendly web application using Streamlit for testing purposes, a popular open-source Python library for building interactive data apps. Streamlit provides a simple and intuitive way to create custom interfaces that can seamlessly integrate with the various AWS services involved in this solution.\n",
    "\n",
    "Here is the application, **don't modify the placeholders, we will replace them in the next cell.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a1b06-6fb0-4c36-a0b0-27319413d8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import streamlit as st\n",
    "from streamlit_cognito_auth import CognitoAuthenticator\n",
    "\n",
    "pool_id = \"<<replace_pool_id>>\"\n",
    "app_client_id = \"<<replace_app_client_id>>\"\n",
    "app_client_secret = \"<<replace_app_client_secret>>\"\n",
    "kb_id = \"<<replace_kb_id>>\"\n",
    "lambda_function_arn = '<<replace_lambda_function_arn>>'\n",
    "dynamo_table = '<<replace_dynamo_table_name>>'\n",
    "\n",
    "authenticator = CognitoAuthenticator(\n",
    "    pool_id=pool_id,\n",
    "    app_client_id=app_client_id,\n",
    "    app_client_secret= app_client_secret,\n",
    "    use_cookies=False\n",
    ")\n",
    "\n",
    "is_logged_in = authenticator.login()\n",
    "\n",
    "if not is_logged_in:\n",
    "    st.stop()\n",
    "\n",
    "def logout():\n",
    "    authenticator.logout()\n",
    "\n",
    "def get_user_sub(user_pool_id, username):\n",
    "    cognito_client = boto3.client('cognito-idp')\n",
    "    try:\n",
    "        response = cognito_client.admin_get_user(\n",
    "            UserPoolId=pool_id,\n",
    "            Username=authenticator.get_username()\n",
    "        )\n",
    "        sub = None\n",
    "        for attr in response['UserAttributes']:\n",
    "            if attr['Name'] == 'sub':\n",
    "                sub = attr['Value']\n",
    "                break\n",
    "        return sub\n",
    "    except cognito_client.exceptions.UserNotFoundException:\n",
    "        print(\"User not found.\")\n",
    "        return None\n",
    "\n",
    "def get_corpus_ids(user_id):\n",
    "    dynamodb = boto3.client('dynamodb')\n",
    "    response = dynamodb.query(\n",
    "        TableName=dynamo_table,\n",
    "        KeyConditionExpression='user_id = :user_id',\n",
    "        ExpressionAttributeValues={\n",
    "            ':user_id': {'S': user_id}\n",
    "        }\n",
    "    )\n",
    "    print(response)\n",
    "    corpus_id_list = []  # Initialize the list\n",
    "    for item in response['Items']:\n",
    "        corpus_ids = item.get('corpus_id_list', {}).get('L', [])\n",
    "        corpus_id_list.extend([corpus_id['S'] for corpus_id in corpus_ids])\n",
    "    return corpus_id_list\n",
    "\n",
    "def search_transcript(user_id, kb_id, text, corpus_ids):\n",
    "    # Initialize the Lambda client\n",
    "    lambda_client = boto3.client('lambda')\n",
    "\n",
    "    # Payload for the Lambda function\n",
    "    payload = json.dumps({\n",
    "        \"userId\": sub,\n",
    "        \"knowledgeBaseId\": kb_id,\n",
    "        \"text\": text, \n",
    "        \"corpusIds\": corpus_ids\n",
    "    }).encode('utf-8')\n",
    "\n",
    "    try:\n",
    "        # Invoke the Lambda function\n",
    "        response = lambda_client.invoke(\n",
    "            FunctionName=lambda_function_arn,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=payload\n",
    "        )\n",
    "\n",
    "        # Process the response\n",
    "        if response['StatusCode'] == 200:\n",
    "            response_payload = json.loads(response['Payload'].read().decode('utf-8'))\n",
    "            return response_payload\n",
    "        else:\n",
    "            # Handle error response\n",
    "            return {'error': 'Failed to fetch data'}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exception\n",
    "        return {'error': str(e)}\n",
    "\n",
    "sub = get_user_sub(pool_id, authenticator.get_username())\n",
    "print(sub)\n",
    "corpus_ids = get_corpus_ids(sub)\n",
    "print(corpus_ids)\n",
    "\n",
    "# Application Front\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"User Information\")\n",
    "    st.markdown(\"## User\")\n",
    "    st.text(authenticator.get_username())\n",
    "    st.markdown(\"## User Id\")\n",
    "    st.text(sub)\n",
    "    # selected_patient = st.selectbox(\"Select a patient (or 'All' for all patients)\", ['All'] + patient_ids)\n",
    "    st.button(\"Logout\", \"logout_btn\", on_click=logout)\n",
    "\n",
    "st.header(\"Corpus Search Tool\")\n",
    "\n",
    "# Text input for the search query\n",
    "query = st.text_input(\"Enter your search query:\")\n",
    "\n",
    "if st.button(\"Search\"):\n",
    "    if query:\n",
    "        # Perform search\n",
    "        corpus_ids_filter = corpus_ids\n",
    "        results = search_transcript(sub, kb_id, query, corpus_ids_filter)\n",
    "        print(results)\n",
    "        if results:\n",
    "            st.subheader(\"Search Results:\")\n",
    "            st.markdown(results[\"body\"], unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(\"No matching results found in corpus.\")\n",
    "    else:\n",
    "        st.write(\"Please enter a search query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b58f02-bfa7-4c8f-80cb-f47c10ad1c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_vars(\"app.py\", user_pool_id, client_id, client_secret, kb_id, lambda_function_arn, dynamo_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4af76d-428f-45df-b082-6f8b2ab15723",
   "metadata": {},
   "source": [
    "#### Execute the streamlit locally\n",
    "Execute the cell below to run the Streamlit application.\n",
    "\n",
    "**Use the email and password of the doctors you defined at the top of the notebook to access the application.**\n",
    "\n",
    "Once you have logged in, you can filter by specific patients you have assigned (dropdown in the left panel), or all to query the knowledge base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a6b85-af35-4283-95fb-eae1c62e9f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd734a82-46cf-48fc-b7fc-a28532b6fd5c",
   "metadata": {},
   "source": [
    "If you are executing this notebook on SageMaker Studio you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<STUDIOID>>.studio.<<REGION>>.sagemaker.aws/jupyterlab/default/proxy/8501/\n",
    "```\n",
    "\n",
    "If you are executing this notebook on a SageMaker Notebook you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<NOTEBOOKID>>.notebook.<<REGION>>.sagemaker.aws/proxy/8501/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1802e91-1826-4399-a3c2-34b787887c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://rxhmevhu84g12we.studio.us-west-2.sagemaker.aws/jupyterlab/default/proxy/8501/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77585073-6684-4662-a78f-20e2d43a7c6f",
   "metadata": {},
   "source": [
    "### 9. Clean up\n",
    "**Before running this cell you will need to stop the cell above where the app is runnning!**\n",
    "\n",
    "Run the following cell to delete the created resources and avoid unnecesary costs. This should take about 2-3 minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ccc8b-a828-416f-9c93-9482c929f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete all objects in the bucket\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=s3_bucket)\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            s3_client.delete_object(Bucket=s3_bucket, Key=obj['Key'])\n",
    "        print(f\"All objects in {s3_bucket} have been deleted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting objects from {s3_bucket}: {e}\")\n",
    "\n",
    "# Define the stack names to delete\n",
    "stack_names = [\"KB-E2E-KB-{}\".format(solution_id),\"KB-E2E-Base-{}\".format(solution_id)]\n",
    "\n",
    "# Iterate over the stack names and delete each stack\n",
    "for stack_name in stack_names:\n",
    "    try:\n",
    "        # Retrieve the stack information\n",
    "        stack_info = cloudformation.describe_stacks(StackName=stack_name)\n",
    "        stack_status = stack_info['Stacks'][0]['StackStatus']\n",
    "\n",
    "        # Check if the stack exists and is in a deletable state\n",
    "        if stack_status != 'DELETE_COMPLETE':\n",
    "            # Delete the stack\n",
    "            cloudformation.delete_stack(StackName=stack_name)\n",
    "            print(f'Deleting stack: {stack_name}')\n",
    "\n",
    "            # Wait for the stack deletion to complete\n",
    "            waiter = cloudformation.get_waiter('stack_delete_complete')\n",
    "            waiter.wait(StackName=stack_name)\n",
    "            print(f'Stack {stack_name} deleted successfully.')\n",
    "        else:\n",
    "            print(f'Stack {stack_name} does not exist or has already been deleted.')\n",
    "\n",
    "    except cloudformation.exceptions.ClientError as e:\n",
    "        print(f'Error deleting stack {stack_name}: {e.response[\"Error\"][\"Message\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
