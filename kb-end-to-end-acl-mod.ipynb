{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1dd3dc-f3f6-457e-acf3-d6fb47ffd0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9691ea2b-3ee8-4742-9ff1-ca933e1bc72d",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock\n",
    "## Access Control Filtering - End to end notebook\n",
    "\n",
    "This notebook will guide the users on creating access controls for Knowledge Bases on Amazon Bedrock.\n",
    "\n",
    "To demonstrate the access control capabilities enabled by metadata filtering in Knowledge Bases, let's consider a use case where you work at a large enterprise, AcmeCorp. At AcmeCorp we want to create a Knowledge Base containing content from various s3 buckets.  However, each user does not have access to all data. A RAG architecture is perfect for this use case since we can restrict the retrieval to only the documents we have access to.  \n",
    "\n",
    "To complete this notebook you should have a role with access to the following services: Amazon S3, AWS STS, AWS Lambda, AWS CloudFormation, Amazon Bedrock, Amazon Cognito and Amazon Opensearch Serverless. \n",
    "\n",
    "This notebook contains the following sections:\n",
    "\n",
    "0. **Base Infrastructure Deployment**: In this section you will deploy an Amazon Cloudformation Template which will create and configure some of the services used for the solution. \n",
    "1. **Amazon Cognito:** You are going to populate an Amazon Cognito pool with three users. We will use the unique identifiers generated by Cognito for each user to associate document corpus with the respective users.\n",
    "2. **User-corpus association in Amazon DynamoDB:** You will populate an Amazon DynamoDB table which will store user-corpus associations. \n",
    "3. **Dataset download:** For this notebook you will use documents provided in an s3 bucket and stored in 3 different folders.\n",
    "4. **Metadata association:** You will use the user identifiers generated by Cognito to create metadata files associated to each corpus.\n",
    "5. **Create OpensearchServerless** You will create an OpenSearch Serverless collection to be used by Amazon Knowledge Base.\n",
    "6. **Create a Knowledge Base for Amazon Bedrock**: You will create and sync the Knowledge Base with the documents and associated metadata.\n",
    "7. **Update AWS Lambda:** Until Boto3/Lambda is updated -- Create a Lambda Layer to include the latest SDK.\n",
    "8. **Create and run a Streamlit Application:** You will create a simple interface to showcase access control with metadata filtering using a Streamlit application\n",
    "9. **Clean up:** Delete all the resources created during this notebook to avoid unnecessary costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51edb0-cae2-4929-b0a5-8a8057c7f467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU opensearch-py streamlit streamlit-cognito-auth retrying boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c10f35-09a3-4e9c-8f73-e9235609ac0b",
   "metadata": {},
   "source": [
    "Let's import necessary Python modules and libraries, and initialize AWS service clients required for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5c3502ca-2256-499d-9d37-70021e379a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import requests\n",
    "import random\n",
    "from utilsmod import create_base_infrastructure, create_kb_infrastructure, updateDataAccessPolicy, createAOSSIndex, replace_vars\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "lambda_client = boto3.client('lambda')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "cloudformation = boto3.client('cloudformation')\n",
    "opensearch = boto3.client('opensearchserverless')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock = boto3.client(\"bedrock\",region_name=region)\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "cognito_client = boto3.client('cognito-idp', region_name=region)\n",
    "identity_arn = session.client('sts').get_caller_identity()['Arn']\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "bucket_name = 'namer' + account_id + '-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee423c-bc86-401c-8bb4-affd884ccfe0",
   "metadata": {},
   "source": [
    "### 0. Base Infrastructure \n",
    "The following has already been created for you by the workshop: \n",
    "\n",
    "- Amazon Cognito User Pool and App Client. (user_pool_id, cognito_arn, client_id, client_secret)\n",
    "- Amazon DynamoDB Table\n",
    "- Amazon S3 Bucket\n",
    "- AWS Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d45776-1ded-4ff3-ad9a-5a7d34610a85",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f6f55-689a-4aae-b3c3-e29883998359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "def short_uuid():\n",
    "    uuid_str = str(uuid.uuid4())\n",
    "    return uuid_str[:8]\n",
    "\n",
    "solution_id = 'KBS{}'.format(short_uuid()).lower()\n",
    "user_pool_id, user_pool_arn, cognito_arn, client_id, client_secret, dynamo_table, s3_bucket, lambda_function_arn, collection_id = create_base_infrastructure(solution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785975c8-dffe-4a3b-b113-50d795e5862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "%store user_pool_id user_pool_arn cognito_arn client_id client_secret dynamo_table s3_bucket lambda_function_arn collection_id solution_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e64b05-9bfb-43e2-8d62-551a7ffb62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40293544-d50a-4bb9-8a4f-e7700590200e",
   "metadata": {},
   "source": [
    "### 1. Amazon Cognito User Pool: Users and Corpus\n",
    "#### Create users and corpus into the user pool\n",
    "We will create users and corpus to test out the use case. User ids are stored for later use when retrieving information.\n",
    "For the notebook to work you will need to replace the placeholder for 2 doctors and 3 patients. This users will be created in the Amazon Cognito user pool and you will later need them to log into the web application. While this is a dummy user creation for test purposes, in production use cases you will need to follow you organization best practices and guidelines to create users. \n",
    "\n",
    "**For this example, the first doctor will have associated the first two patients, and the second doctor will have associated the third patient.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc1b6e-1b68-49c8-b111-be43ac493294",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> \n",
    "<br><b>Password minimum length:</b>8 character(s)\n",
    "<br><b>Password requirements</b>\n",
    "<br>Contains at least 1 number\n",
    "<br>Contains at least 1 special character\n",
    "<br>Contains at least 1 uppercase letter\n",
    "<br>Contains at least 1 lowercase letter\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7b1dc-08a2-4d89-972f-dddb1a3d0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "    {\n",
    "        'name': 'Highway Harry',\n",
    "        'email': 'highway.harry@acmecorp.com',\n",
    "        'password': 'Highway.Harry.123$',\n",
    "        'corpus': ['highway']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wildlife Walter',\n",
    "        'email': 'wildlife.walter@acmecorp.com',\n",
    "        'password': 'Wildlife.Walter.123$',\n",
    "        'corpus': ['wildlife']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Admin Amy',\n",
    "        'email': 'admin.amy@acmecorp.com',\n",
    "        'password': 'Admin.Amy.123$',\n",
    "        'corpus': ['highway', 'wildlife']\n",
    "    },\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    {\n",
    "        'name': 'highway',\n",
    "        'description': 'document regarding highway and roadsign regulations',\n",
    "        's3path': f\"s3://{s3_bucket}/highway/\"\n",
    "    },\n",
    "    {\n",
    "        'name': 'wildlife',\n",
    "        'description': 'documents regarding fishing and hunting regulations',\n",
    "        's3path': f's3://{s3_bucket}/wildlife/'\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131a29e-c8b0-4446-b00f-638f90b8ab98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_ids = []\n",
    "corpus_ids = []\n",
    "\n",
    "def create_user(user_data, user_type):\n",
    "    user_ids = []\n",
    "    for user in user_data:\n",
    "        response = cognito_client.admin_create_user(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            UserAttributes=[\n",
    "                {'Name': 'name', 'Value': user['name']},\n",
    "                {'Name': 'email', 'Value': user['email']},\n",
    "                {'Name': 'email_verified', 'Value': 'true'}\n",
    "            ],\n",
    "            ForceAliasCreation=False,\n",
    "            MessageAction='SUPPRESS'\n",
    "        )\n",
    "        cognito_client.admin_set_user_password(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            Password=user['password'],\n",
    "            Permanent=True\n",
    "        )\n",
    "        print(f\"{user_type.capitalize()} created:\", response['User']['Username'])\n",
    "        print(f\"{user_type.capitalize()} id:\", response['User']['Attributes'][3]['Value'])\n",
    "        user_ids.append(response['User']['Attributes'][3]['Value'])\n",
    "    return user_ids\n",
    "\n",
    "user_ids = create_user(users, 'user')\n",
    "corpus_ids = [str(uuid.uuid4()) for c in corpus]\n",
    "\n",
    "print(\"User IDs:\", user_ids)\n",
    "print(\"Corpus IDs:\", corpus_ids)\n",
    "\n",
    "%store user_ids corpus_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293facc-39be-46eb-a7e9-696a1084c679",
   "metadata": {},
   "source": [
    "### 2. User-corpus association in DynamoDB\n",
    "In this section we will populate the already created DynamoDB table with the user-corpus associations. This will be useful later on to retrieve the list of corpus ids a user is allowed to filter by. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15faadd4-960f-47ed-8793-b65fc2a65e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = dynamodb_resource.Table(dynamo_table)\n",
    "corpus_mapping = [entry['name'] for entry in corpus]\n",
    "with table.batch_writer() as batch:\n",
    "    for corpus,user in enumerate(users):\n",
    "        temp = []\n",
    "        for corpus_id,corpuses in enumerate(corpus_mapping):\n",
    "            if corpuses in user['corpus']:\n",
    "                temp.append(corpus_ids[corpus_id])\n",
    "\n",
    "        batch.put_item(\n",
    "            Item={\n",
    "                'user_id': user_ids[corpus],\n",
    "                'corpus_id_list': temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "print('Data inserted successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cda19f76-ae71-4862-9f79-b1a5d7b2a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: source_transcripts/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf to s3://bucket_name/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf to s3://bucket_name/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/Loon - Wikipedia.pdf to s3://bucket_name/wildlife/Loon - Wikipedia.pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'namer' + account_id + '-bucket'\n",
    "!aws s3 cp ./source_transcripts/ s3://bucket_name/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8769a-b265-4cb9-bdb3-599ff4be305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the corpus and their corresponding IDs\n",
    "for corpuses, corpus_entry in enumerate(corpus):\n",
    "    corpus_id = corpus_ids[corpuses]\n",
    "    s3path = corpus_entry['s3path']\n",
    "    \n",
    "    # Get bucket and prefix\n",
    "    # Remove 's3://' and split bucket and prefix\n",
    "    path_parts = s3path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    prefix = path_parts[1] if len(path_parts) > 1 else ''\n",
    "    \n",
    "    # List all files in the S3 folder\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        files = [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    else:\n",
    "        files = []\n",
    "    \n",
    "    for file in files:\n",
    "        metadata = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"corpus_id\": corpus_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload metadata file to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key=f\"{file}.metadata.json\",\n",
    "            Body=json.dumps(metadata, indent=4),\n",
    "            ContentType='application/json'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0474937-035d-4900-a877-dca3c674b45e",
   "metadata": {},
   "source": [
    "### 5. Upload to Amazon S3\n",
    "Knowledge Bases for Amazon Bedrock, currently require data to reside in an Amazon S3 bucket. We will upload both files and metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700ad37-73b8-4200-a7da-efe66ae02f1f",
   "metadata": {},
   "source": [
    "### 6. Create OpensearchServerless\n",
    "\n",
    "In this section we will create all the policies for the OpenSearch Serverless Collection and then create the collection itself.\n",
    "\n",
    "First we will create an encryption policy for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "489ef438-e4da-4657-a1e3-8a4de72b36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Rules\":[{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-431615879134-kbcollection\"]}], \"AWSOwnedKey\": true}\n",
      "{'securityPolicyDetail': {'createdDate': 1725552314705, 'description': 'Public encryption access namer workshop collection', 'lastModifiedDate': 1725552314705, 'name': 'namer-431615879134-kbenc', 'policy': {'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'ResourceType': 'collection'}], 'AWSOwnedKey': True}, 'policyVersion': 'MTcyNTU1MjMxNDcwNV8x', 'type': 'encryption'}, 'ResponseMetadata': {'RequestId': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'date': 'Thu, 05 Sep 2024 16:05:14 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '375', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '{{\"Rules\":[{{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-{0}-kbcollection\"]}}], \"AWSOwnedKey\": true}}'.format(account_id)\n",
    "print(policy)\n",
    "\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public encryption access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbenc',\n",
    "    policy=policy,\n",
    "    type='encryption'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89f434-c101-4495-8975-95873957d7a9",
   "metadata": {},
   "source": [
    "Now we will create a Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "09cf22ad-37ef-4c0f-ac9c-5a2f8070022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Rules\": [{\"ResourceType\": \"dashboard\", \n",
      "    \"Resource\": [\"collection/namer-431615879134-kbcollection\"]}, \n",
      "    {\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer431615879134-kbcollection\"]}], \n",
      "    \"AllowFromPublic\": true}]\n",
      "{'securityPolicyDetail': {'createdDate': 1725554665546, 'description': 'Public network access namer workshop collection', 'lastModifiedDate': 1725554665546, 'name': 'namer-431615879134-kbnet', 'policy': [{'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'ResourceType': 'dashboard'}, {'Resource': ['collection/namer431615879134-kbcollection'], 'ResourceType': 'collection'}], 'AllowFromPublic': True}], 'policyVersion': 'MTcyNTU1NDY2NTU0Nl8x', 'type': 'network'}, 'ResponseMetadata': {'RequestId': '3d5037df-ae23-448c-8be9-ab57bb0a1525', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3d5037df-ae23-448c-8be9-ab57bb0a1525', 'date': 'Thu, 05 Sep 2024 16:44:25 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '461', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '''[{{\"Rules\": [{{\"ResourceType\": \"dashboard\", \n",
    "    \"Resource\": [\"collection/namer-{0}-kbcollection\"]}}, \n",
    "    {{\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer{0}-kbcollection\"]}}], \n",
    "    \"AllowFromPublic\": true}}]'''.format(account_id)\n",
    "print(policy)\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public network access namer workshop collection',\n",
    "    name='namer-{0}-kbnet'.format(account_id),\n",
    "    policy=policy,\n",
    "    type='network'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d0935-28c4-4013-9a58-434a68abd5ca",
   "metadata": {},
   "source": [
    "Next we need to create the Data Access Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "09a89b4c-61c3-4ef3-9ac1-de2ccd43d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Rules\": [{\"Resource\": [\"collection/namer-431615879134-kbcollection\"], \n",
      "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
      "                           \"ResourceType\": \"collection\"}, \n",
      "                          {\"ResourceType\": \"index\", \"Resource\": [\"index/namer-431615879134-kbcollection/*\"], \n",
      "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}], \n",
      "                \"Principal\": [\"arn:aws:iam::431615879134:role/namer-431615879134-kbrole\"]}]\n"
     ]
    }
   ],
   "source": [
    "policy = '''[{{\"Rules\": [{{\"Resource\": [\"collection/namer-{0}-kbcollection\"], \n",
    "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
    "                           \"ResourceType\": \"collection\"}}, \n",
    "                          {{\"ResourceType\": \"index\", \"Resource\": [\"index/namer-{0}-kbcollection/*\"], \n",
    "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}}], \n",
    "                \"Principal\": [\"arn:aws:iam::{0}:role/namer-{0}-kbrole\"]}}]'''.format(account_id)\n",
    "print(policy)\n",
    "results = opensearch.create_access_policy(\n",
    "    description='Data access policy for the NAMER summit',\n",
    "    name='namer-{0}-kbaccess'.format(account_id),\n",
    "    policy=policy,\n",
    "    type='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66443aa1-802a-406c-b58d-9bbb4c2cf4c9",
   "metadata": {},
   "source": [
    "Now that we have our policies we can create the OpenSearch Serverless Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6fb4e8f0-2b25-4de2-b947-1ced00c3a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = opensearch.create_collection(\n",
    "    description='KB AOSS Collection',\n",
    "    name='namer-{0}-kbcollection'.format(account_id),\n",
    "    type='VECTORSEARCH'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f7a64-933f-4e80-a722-98c0680e5bae",
   "metadata": {},
   "source": [
    "Creating the collection takes some time so we will check to see if it has been created yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8c342988-f55c-4628-a0f1-e73cc9ed82f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collectionSummaries': [{'arn': 'arn:aws:aoss:us-west-2:431615879134:collection/u2wtftrxpiq8u7r314r0', 'id': 'u2wtftrxpiq8u7r314r0', 'name': 'namer-431615879134-kbcollection', 'status': 'ACTIVE'}], 'ResponseMetadata': {'RequestId': 'e8ec1a07-c06c-4e01-a1a2-76d97d2645ee', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e8ec1a07-c06c-4e01-a1a2-76d97d2645ee', 'date': 'Thu, 05 Sep 2024 17:03:27 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '190', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "Collection created\n"
     ]
    }
   ],
   "source": [
    "response = opensearch.list_collections(collectionFilters={'name':'namer-{0}-kbcollection'.format(account_id)})\n",
    "collection_id = response[\"collectionSummaries\"][0][\"id\"]\n",
    "while response[\"collectionSummaries\"][0][\"status\"] != \"ACTIVE\":\n",
    "    wait(10)\n",
    "\n",
    "print(\"Collection created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72a007-409f-4c32-be0c-1e73bf868d4b",
   "metadata": {},
   "source": [
    "### 7. Create a Knowledge Base for Amazon Bedrock\n",
    "\n",
    "In this section we will go through all the steps to create and test a Knowledge Base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "37b62c6a-08e1-48c1-9432-e230d0df30ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index name: namer-431615879134-kb-acl-index\n",
      "Stored 'indexName' (str)\n"
     ]
    }
   ],
   "source": [
    "indexName = \"namer-{0}-kb-acl-index\".format(account_id)\n",
    "print(\"Index name:\",indexName)\n",
    "%store indexName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a583a886-dbdd-4edd-abd9-246ebcda02cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessPolicyDetail': {'createdDate': 1725554790042, 'description': 'dataAccessPolicy', 'lastModifiedDate': 1725557089030, 'name': 'namer-431615879134-kbaccess', 'policy': [{'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'Permission': ['aoss:CreateCollectionItems', 'aoss:UpdateCollectionItems', 'aoss:DescribeCollectionItems'], 'ResourceType': 'collection'}, {'Resource': ['index/namer-431615879134-kbcollection/*'], 'Permission': ['aoss:CreateIndex', 'aoss:DescribeIndex', 'aoss:ReadDocument', 'aoss:WriteDocument', 'aoss:UpdateIndex', 'aoss:DeleteIndex'], 'ResourceType': 'index'}], 'Principal': ['arn:aws:iam::431615879134:role/namer-431615879134-kbrole', 'arn:aws:sts::431615879134:assumed-role/namer-summit-2024/SageMaker']}], 'policyVersion': 'MTcyNTU1NzA4OTAzMF8y', 'type': 'data'}, 'ResponseMetadata': {'RequestId': '6ffa318b-9783-400b-bf1e-d4854c066b89', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '6ffa318b-9783-400b-bf1e-d4854c066b89', 'date': 'Thu, 05 Sep 2024 17:24:49 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '779', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "Finished adding the role\n"
     ]
    }
   ],
   "source": [
    "# Adding the current role to the collection's data access policy\n",
    "data_access_policy_name = 'namer-{0}-kbaccess'.format(account_id)\n",
    "current_role_arn = sts_client.get_caller_identity()['Arn']\n",
    "response = opensearch.get_access_policy(\n",
    "    name=data_access_policy_name,\n",
    "    type='data'\n",
    ")\n",
    "policy_version = response[\"accessPolicyDetail\"][\"policyVersion\"]\n",
    "existing_policy = response['accessPolicyDetail']['policy']\n",
    "updated_policy = existing_policy.copy()\n",
    "updated_policy[0]['Principal'].append(current_role_arn)\n",
    "updated_policy = str(updated_policy).replace(\"'\", '\"')\n",
    "\n",
    "response = opensearch.update_access_policy(\n",
    "    description='dataAccessPolicy',\n",
    "    name=data_access_policy_name,\n",
    "    policy=updated_policy,\n",
    "    policyVersion=policy_version,\n",
    "    type='data'\n",
    ")\n",
    "print(response)\n",
    "\n",
    "time.sleep(60) # Changes to the data access policy might take a bit to update\n",
    "print(\"Finished adding the role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dbd0b5e4-1e5c-4659-9192-5fe4dbc844f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'namer-431615879134-kb-acl-index'}\n"
     ]
    }
   ],
   "source": [
    "# Set up AWS authentication\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "# Define index settings and mappings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": \"true\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                 \"method\": {\n",
    "                     \"name\": \"hnsw\",\n",
    "                     \"engine\": \"faiss\",\n",
    "                     \"space_type\": \"innerproduct\",\n",
    "                     \"parameters\": {\n",
    "                         \"ef_construction\": 512,\n",
    "                         \"m\": 16\n",
    "                     },\n",
    "                 },\n",
    "             },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"text-metadata\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build the OpenSearch client\n",
    "host = f\"{collection_id}.{region}.aoss.amazonaws.com\"\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Create index\n",
    "response = oss_client.indices.create(index=indexName, body=json.dumps(index_settings))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e004121-cec0-4f79-a873-c5716d2eeea5",
   "metadata": {},
   "source": [
    "#### Create the Knowledge Base\n",
    "In this section you will create the Knowledge Base. Before creating a new KB we need to define which embeddings model we want it to use. In this case we will be using Amazon Titan Embeddings V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b7170-055f-4f34-be59-2f153f1f74c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Amazon Titan Embeddings V2 access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5470be25-3c79-4eb0-b3bf-c419c1878a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModelArn = \"arn:aws:bedrock:{}::foundation-model/amazon.titan-embed-text-v2:0\".format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5d386-bd9b-4d0e-b660-4fb347ad07fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create our Knowledge Base for Amazon Bedrock. We have created an Amazon CloudFormation template which takes care of the configuration needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b087b-b5b1-4024-9149-b4026dd74450",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "951db5fd-d6ca-48f8-8803-4cbd3b50bf2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AlreadyExistsException",
     "evalue": "An error occurred (AlreadyExistsException) when calling the CreateStack operation: Stack [KB-E2E-KB-john38396d21] already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAlreadyExistsException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kb_id, datasource_id \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_kb_infrastructure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_bucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddingModelArn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccount_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/namer-summit-2024-genAI-privacy/utilsmod.py:110\u001b[0m, in \u001b[0;36mcreate_kb_infrastructure\u001b[0;34m(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Create the CloudFormation stack\u001b[39;00m\n\u001b[1;32m    109\u001b[0m stack_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKB-E2E-KB-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(solution_id)\n\u001b[0;32m--> 110\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcloudformation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_stack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mStackName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTemplateBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mParameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCapabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCAPABILITY_IAM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCAPABILITY_AUTO_EXPAND\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCAPABILITY_NAMED_IAM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m stack_id \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStackId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStack creation initiated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mAlreadyExistsException\u001b[0m: An error occurred (AlreadyExistsException) when calling the CreateStack operation: Stack [KB-E2E-KB-john38396d21] already exists"
     ]
    }
   ],
   "source": [
    "kb_id, datasource_id = create_kb_infrastructure(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f94c5-0e4f-4dfe-8ee4-5e5fd4478773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store kb_id datasource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3b55c-2b32-4375-9959-9ff502240620",
   "metadata": {},
   "source": [
    "#### Sync the Knowledge Base\n",
    "As we have created and associated the data source to the Knowledge Base, we can proceed to Sync the data. \n",
    "\n",
    "\n",
    "Each time you add, modify, or remove files from the S3 bucket for a data source, you must sync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon Bedrock only processes the objects in your S3 bucket that have been added, modified, or deleted since the last sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9c800-6e86-4fee-b09a-b8f4777d7fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingestion_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id,\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial Ingestion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e2bbf-6a21-4cfd-95e4-2102fdcb3b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "    dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "    ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    ")[\"ingestionJob\"][\"status\"]\n",
    "print(status)\n",
    "while status not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "    status = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "        dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "        ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    "    )[\"ingestionJob\"][\"status\"]\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "print(\"Waiting for changes to take place in the vector database\")\n",
    "time.sleep(30) # Wait for all changes to take place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b18f36-41ec-4083-a4f9-a08fc5ed3144",
   "metadata": {},
   "source": [
    "#### Test the Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the **retrieve** and **retrieve_and_generate** APIs.\n",
    "\n",
    "Let's examine a test case with patient 0's transcript, where they mention a cat named Kelly. We'll query the knowledge base using the metadata filter for patient 0 to retrieve information about Kelly. Changing the patient_id will prevent the model from responding accurately. Read through the PDFs for other questions you might want to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30d7f7-77e7-4745-a10f-3956d7f02b2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this first example we are going to use the **retrieve and generate API**. This API queries a knowledge base and generates responses based on the retrieved results, using an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b971c-e879-4d81-81c1-365f052523f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Anthropic Claude 3 Sonnet access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452bb02-651f-4d3f-8480-6eddb4b7f898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve and generate API\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"Which office do I submit for golden eagle permits?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\".format(region),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5,\n",
    "                    \"filter\": {\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"corpus_id\",\n",
    "                            \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2f8dd-aae4-4461-aa65-0f82cc74abc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this second example we are going to use the **retrieve API**. This API queries the knowledge base and retrieves relavant information from it, it does not generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b737f1-0c49-42b6-948b-62c931616d43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":3,\n",
    "            \"filter\": {\n",
    "                 \"equals\": {\n",
    "                    \"key\": \"corpus_id\",\n",
    "                    \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "    retrievalQuery={\n",
    "        'text': \"Which office do I submit for golden eagle permits?\"\n",
    "            \n",
    "        }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents\n",
    "# each list has content,location,score,metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9564b45-90ab-4b21-9fe6-e6ab62ae7282",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock\n",
    "## Access Control Filtering - End to end notebook\n",
    "\n",
    "This notebook will guide the users on creating access controls for Knowledge Bases on Amazon Bedrock.\n",
    "\n",
    "To demonstrate the access control capabilities enabled by metadata filtering in Knowledge Bases, let's consider a use case where you work at a large enterprise, AcmeCorp. At AcmeCorp we want to create a Knowledge Base containing content from various s3 buckets.  However, each user does not have access to all data. A RAG architecture is perfect for this use case since we can restrict the retrieval to only the documents we have access to.  \n",
    "\n",
    "To complete this notebook you should have a role with access to the following services: Amazon S3, AWS STS, AWS Lambda, AWS CloudFormation, Amazon Bedrock, Amazon Cognito and Amazon Opensearch Serverless. \n",
    "\n",
    "This notebook contains the following sections:\n",
    "\n",
    "0. **Base Infrastructure Deployment**: In this section you will deploy an Amazon Cloudformation Template which will create and configure some of the services used for the solution. \n",
    "1. **Amazon Cognito:** You are going to populate an Amazon Cognito pool with three users. We will use the unique identifiers generated by Cognito for each user to associate document corpus with the respective users.\n",
    "2. **User-corpus association in Amazon DynamoDB:** You will populate an Amazon DynamoDB table which will store user-corpus associations. \n",
    "3. **Dataset download:** For this notebook you will use documents provided in an s3 bucket and stored in 3 different folders.\n",
    "4. **Metadata association:** You will use the user identifiers generated by Cognito to create metadata files associated to each corpus.\n",
    "5. **Create OpensearchServerless** You will create an OpenSearch Serverless collection to be used by Amazon Knowledge Base.\n",
    "6. **Create a Knowledge Base for Amazon Bedrock**: You will create and sync the Knowledge Base with the documents and associated metadata.\n",
    "7. **Update AWS Lambda:** Until Boto3/Lambda is updated -- Create a Lambda Layer to include the latest SDK.\n",
    "8. **Create and run a Streamlit Application:** You will create a simple interface to showcase access control with metadata filtering using a Streamlit application\n",
    "9. **Clean up:** Delete all the resources created during this notebook to avoid unnecessary costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b462b80-336a-4b46-abf8-bc11f61ff7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU opensearch-py streamlit streamlit-cognito-auth retrying boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7491c16-bed6-4d49-a0a2-d33295790547",
   "metadata": {},
   "source": [
    "Let's import necessary Python modules and libraries, and initialize AWS service clients required for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "aca40823-5436-4d7f-b914-5742ef180829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import requests\n",
    "import random\n",
    "from utilsmod import create_base_infrastructure, create_kb_infrastructure, updateDataAccessPolicy, createAOSSIndex, replace_vars\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "lambda_client = boto3.client('lambda')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "cloudformation = boto3.client('cloudformation')\n",
    "opensearch = boto3.client('opensearchserverless')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock = boto3.client(\"bedrock\",region_name=region)\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "cognito_client = boto3.client('cognito-idp', region_name=region)\n",
    "identity_arn = session.client('sts').get_caller_identity()['Arn']\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "bucket_name = 'namer' + account_id + '-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc15dd-5046-48a5-97ea-27078be933fd",
   "metadata": {},
   "source": [
    "### 0. Base Infrastructure \n",
    "The following has already been created for you by the workshop: \n",
    "\n",
    "- Amazon Cognito User Pool and App Client. (user_pool_id, cognito_arn, client_id, client_secret)\n",
    "- Amazon DynamoDB Table\n",
    "- Amazon S3 Bucket\n",
    "- AWS Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b05b7f-989e-4bc3-8264-fd9be00a6840",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae55ff-886b-4ce2-af23-b3eac0be74c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "def short_uuid():\n",
    "    uuid_str = str(uuid.uuid4())\n",
    "    return uuid_str[:8]\n",
    "\n",
    "solution_id = 'KBS{}'.format(short_uuid()).lower()\n",
    "user_pool_id, user_pool_arn, cognito_arn, client_id, client_secret, dynamo_table, s3_bucket, lambda_function_arn, collection_id = create_base_infrastructure(solution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66552677-1b75-411d-a59f-c7b35d725176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "%store user_pool_id user_pool_arn cognito_arn client_id client_secret dynamo_table s3_bucket lambda_function_arn collection_id solution_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee122ea-7d9d-4d71-89ed-18ff0c855c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3191f-dfe5-4f5c-8f57-ee4008ae68f7",
   "metadata": {},
   "source": [
    "### 1. Amazon Cognito User Pool: Users and Corpus\n",
    "#### Create users and corpus into the user pool\n",
    "We will create users and corpus to test out the use case. User ids are stored for later use when retrieving information.\n",
    "For the notebook to work you will need to replace the placeholder for 2 doctors and 3 patients. This users will be created in the Amazon Cognito user pool and you will later need them to log into the web application. While this is a dummy user creation for test purposes, in production use cases you will need to follow you organization best practices and guidelines to create users. \n",
    "\n",
    "**For this example, the first doctor will have associated the first two patients, and the second doctor will have associated the third patient.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167b4f6-3817-4c73-b6dd-d4015d8a8836",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> \n",
    "<br><b>Password minimum length:</b>8 character(s)\n",
    "<br><b>Password requirements</b>\n",
    "<br>Contains at least 1 number\n",
    "<br>Contains at least 1 special character\n",
    "<br>Contains at least 1 uppercase letter\n",
    "<br>Contains at least 1 lowercase letter\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b55c5-4f30-46ba-b386-ecb3289514cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "    {\n",
    "        'name': 'Highway Harry',\n",
    "        'email': 'highway.harry@acmecorp.com',\n",
    "        'password': 'Highway.Harry.123$',\n",
    "        'corpus': ['highway']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wildlife Walter',\n",
    "        'email': 'wildlife.walter@acmecorp.com',\n",
    "        'password': 'Wildlife.Walter.123$',\n",
    "        'corpus': ['wildlife']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Admin Amy',\n",
    "        'email': 'admin.amy@acmecorp.com',\n",
    "        'password': 'Admin.Amy.123$',\n",
    "        'corpus': ['highway', 'wildlife']\n",
    "    },\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    {\n",
    "        'name': 'highway',\n",
    "        'description': 'document regarding highway and roadsign regulations',\n",
    "        's3path': f\"s3://{s3_bucket}/highway/\"\n",
    "    },\n",
    "    {\n",
    "        'name': 'wildlife',\n",
    "        'description': 'documents regarding fishing and hunting regulations',\n",
    "        's3path': f's3://{s3_bucket}/wildlife/'\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea64e4-1908-4c55-bf85-98a296c97bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_ids = []\n",
    "corpus_ids = []\n",
    "\n",
    "def create_user(user_data, user_type):\n",
    "    user_ids = []\n",
    "    for user in user_data:\n",
    "        response = cognito_client.admin_create_user(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            UserAttributes=[\n",
    "                {'Name': 'name', 'Value': user['name']},\n",
    "                {'Name': 'email', 'Value': user['email']},\n",
    "                {'Name': 'email_verified', 'Value': 'true'}\n",
    "            ],\n",
    "            ForceAliasCreation=False,\n",
    "            MessageAction='SUPPRESS'\n",
    "        )\n",
    "        cognito_client.admin_set_user_password(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            Password=user['password'],\n",
    "            Permanent=True\n",
    "        )\n",
    "        print(f\"{user_type.capitalize()} created:\", response['User']['Username'])\n",
    "        print(f\"{user_type.capitalize()} id:\", response['User']['Attributes'][3]['Value'])\n",
    "        user_ids.append(response['User']['Attributes'][3]['Value'])\n",
    "    return user_ids\n",
    "\n",
    "user_ids = create_user(users, 'user')\n",
    "corpus_ids = [str(uuid.uuid4()) for c in corpus]\n",
    "\n",
    "print(\"User IDs:\", user_ids)\n",
    "print(\"Corpus IDs:\", corpus_ids)\n",
    "\n",
    "%store user_ids corpus_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854fe99-5681-416b-99f1-bb720bd80b21",
   "metadata": {},
   "source": [
    "### 2. User-corpus association in DynamoDB\n",
    "In this section we will populate the already created DynamoDB table with the user-corpus associations. This will be useful later on to retrieve the list of corpus ids a user is allowed to filter by. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d9e95-fed8-4fd6-93a8-d1021faec77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = dynamodb_resource.Table(dynamo_table)\n",
    "corpus_mapping = [entry['name'] for entry in corpus]\n",
    "with table.batch_writer() as batch:\n",
    "    for corpus,user in enumerate(users):\n",
    "        temp = []\n",
    "        for corpus_id,corpuses in enumerate(corpus_mapping):\n",
    "            if corpuses in user['corpus']:\n",
    "                temp.append(corpus_ids[corpus_id])\n",
    "\n",
    "        batch.put_item(\n",
    "            Item={\n",
    "                'user_id': user_ids[corpus],\n",
    "                'corpus_id_list': temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "print('Data inserted successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4e09ff47-8811-4ada-b0af-af43d98d46ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: source_transcripts/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf to s3://bucket_name/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf to s3://bucket_name/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/Loon - Wikipedia.pdf to s3://bucket_name/wildlife/Loon - Wikipedia.pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'namer' + account_id + '-bucket'\n",
    "!aws s3 cp ./source_transcripts/ s3://bucket_name/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db798dc0-a6d7-457d-9a7c-f5264a368500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the corpus and their corresponding IDs\n",
    "for corpuses, corpus_entry in enumerate(corpus):\n",
    "    corpus_id = corpus_ids[corpuses]\n",
    "    s3path = corpus_entry['s3path']\n",
    "    \n",
    "    # Get bucket and prefix\n",
    "    # Remove 's3://' and split bucket and prefix\n",
    "    path_parts = s3path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    prefix = path_parts[1] if len(path_parts) > 1 else ''\n",
    "    \n",
    "    # List all files in the S3 folder\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        files = [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    else:\n",
    "        files = []\n",
    "    \n",
    "    for file in files:\n",
    "        metadata = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"corpus_id\": corpus_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload metadata file to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key=f\"{file}.metadata.json\",\n",
    "            Body=json.dumps(metadata, indent=4),\n",
    "            ContentType='application/json'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37681b7-9a57-4dff-a154-88b41d2fe68b",
   "metadata": {},
   "source": [
    "### 5. Upload to Amazon S3\n",
    "Knowledge Bases for Amazon Bedrock, currently require data to reside in an Amazon S3 bucket. We will upload both files and metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa83f8f-33b2-4ce8-824f-5460e6dc920e",
   "metadata": {},
   "source": [
    "### 6. Create OpensearchServerless\n",
    "\n",
    "In this section we will create all the policies for the OpenSearch Serverless Collection and then create the collection itself.\n",
    "\n",
    "First we will create an encryption policy for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b2460c6a-a59a-4d41-b9a1-7c864fb93e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Rules\":[{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-431615879134-kbcollection\"]}], \"AWSOwnedKey\": true}\n",
      "{'securityPolicyDetail': {'createdDate': 1725552314705, 'description': 'Public encryption access namer workshop collection', 'lastModifiedDate': 1725552314705, 'name': 'namer-431615879134-kbenc', 'policy': {'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'ResourceType': 'collection'}], 'AWSOwnedKey': True}, 'policyVersion': 'MTcyNTU1MjMxNDcwNV8x', 'type': 'encryption'}, 'ResponseMetadata': {'RequestId': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'date': 'Thu, 05 Sep 2024 16:05:14 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '375', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '{{\"Rules\":[{{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-{0}-kbcollection\"]}}], \"AWSOwnedKey\": true}}'.format(account_id)\n",
    "print(policy)\n",
    "\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public encryption access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbenc',\n",
    "    policy=policy,\n",
    "    type='encryption'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165b29d-ffd0-4a7b-878a-09970039a8da",
   "metadata": {},
   "source": [
    "Now we will create a Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "73f559df-cb45-4878-8868-1cf05831d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Rules\": [{\"ResourceType\": \"dashboard\", \n",
      "    \"Resource\": [\"collection/namer-431615879134-kbcollection\"]}, \n",
      "    {\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer431615879134-kbcollection\"]}], \n",
      "    \"AllowFromPublic\": true}]\n",
      "{'securityPolicyDetail': {'createdDate': 1725554665546, 'description': 'Public network access namer workshop collection', 'lastModifiedDate': 1725554665546, 'name': 'namer-431615879134-kbnet', 'policy': [{'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'ResourceType': 'dashboard'}, {'Resource': ['collection/namer431615879134-kbcollection'], 'ResourceType': 'collection'}], 'AllowFromPublic': True}], 'policyVersion': 'MTcyNTU1NDY2NTU0Nl8x', 'type': 'network'}, 'ResponseMetadata': {'RequestId': '3d5037df-ae23-448c-8be9-ab57bb0a1525', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3d5037df-ae23-448c-8be9-ab57bb0a1525', 'date': 'Thu, 05 Sep 2024 16:44:25 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '461', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '''[{{\"Rules\": [{{\"ResourceType\": \"dashboard\", \n",
    "    \"Resource\": [\"collection/namer-{0}-kbcollection\"]}}, \n",
    "    {{\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer{0}-kbcollection\"]}}], \n",
    "    \"AllowFromPublic\": true}}]'''.format(account_id)\n",
    "print(policy)\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public network access namer workshop collection',\n",
    "    name='namer-{0}-kbnet'.format(account_id),\n",
    "    policy=policy,\n",
    "    type='network'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4e2de-f970-479a-9319-d760247fa6c8",
   "metadata": {},
   "source": [
    "Next we need to create the Data Access Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b1e9566f-495a-4c93-be42-fdc25399f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Rules\": [{\"Resource\": [\"collection/namer-431615879134-kbcollection\"], \n",
      "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
      "                           \"ResourceType\": \"collection\"}, \n",
      "                          {\"ResourceType\": \"index\", \"Resource\": [\"index/namer-431615879134-kbcollection/*\"], \n",
      "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}], \n",
      "                \"Principal\": [\"arn:aws:iam::431615879134:role/namer-431615879134-kbrole\"]}]\n"
     ]
    }
   ],
   "source": [
    "policy = '''[{{\"Rules\": [{{\"Resource\": [\"collection/namer-{0}-kbcollection\"], \n",
    "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
    "                           \"ResourceType\": \"collection\"}}, \n",
    "                          {{\"ResourceType\": \"index\", \"Resource\": [\"index/namer-{0}-kbcollection/*\"], \n",
    "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}}], \n",
    "                \"Principal\": [\"arn:aws:iam::{0}:role/namer-{0}-kbrole\"]}}]'''.format(account_id)\n",
    "print(policy)\n",
    "results = opensearch.create_access_policy(\n",
    "    description='Data access policy for the NAMER summit',\n",
    "    name='namer-{0}-kbaccess'.format(account_id),\n",
    "    policy=policy,\n",
    "    type='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1e8cc-6acd-49d3-bd42-95590fc3451a",
   "metadata": {},
   "source": [
    "Now that we have our policies we can create the OpenSearch Serverless Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1e7f1be2-4ffc-432e-a22b-fa80eec9ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = opensearch.create_collection(\n",
    "    description='KB AOSS Collection',\n",
    "    name='namer-{0}-kbcollection'.format(account_id),\n",
    "    type='VECTORSEARCH'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa70c56-5819-4863-8ff0-3dddc452f250",
   "metadata": {},
   "source": [
    "Creating the collection takes some time so we will check to see if it has been created yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "18192295-3f4b-4454-afde-58dbfd5d3b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collectionSummaries': [{'arn': 'arn:aws:aoss:us-west-2:431615879134:collection/u2wtftrxpiq8u7r314r0', 'id': 'u2wtftrxpiq8u7r314r0', 'name': 'namer-431615879134-kbcollection', 'status': 'ACTIVE'}], 'ResponseMetadata': {'RequestId': 'e8ec1a07-c06c-4e01-a1a2-76d97d2645ee', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e8ec1a07-c06c-4e01-a1a2-76d97d2645ee', 'date': 'Thu, 05 Sep 2024 17:03:27 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '190', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "Collection created\n"
     ]
    }
   ],
   "source": [
    "response = opensearch.list_collections(collectionFilters={'name':'namer-{0}-kbcollection'.format(account_id)})\n",
    "collection_id = response[\"collectionSummaries\"][0][\"id\"]\n",
    "while response[\"collectionSummaries\"][0][\"status\"] != \"ACTIVE\":\n",
    "    wait(10)\n",
    "\n",
    "print(\"Collection created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9dda6-f2e7-441b-a655-fc909bdc88ba",
   "metadata": {},
   "source": [
    "### 7. Create a Knowledge Base for Amazon Bedrock\n",
    "\n",
    "In this section we will go through all the steps to create and test a Knowledge Base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1790213c-88e2-45b0-80bd-1bf364273e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexName = \"namer-{0}-kb-acl-index-\".format(account_id)\n",
    "print(\"Index name:\",indexName)\n",
    "%store indexName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de6e1d-b54a-4d8c-a47a-c756647bb86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding the current role to the collection's data access policy\n",
    "data_access_policy_name = namer-{0}-kbaccess'.format(account_id)\n",
    "current_role_arn = sts_client.get_caller_identity()['Arn']\n",
    "response = opensearch_client.get_access_policy(\n",
    "    name=data_access_policy_name,\n",
    "    type='data'\n",
    ")\n",
    "policy_version = response[\"accessPolicyDetail\"][\"policyVersion\"]\n",
    "existing_policy = response['accessPolicyDetail']['policy']\n",
    "updated_policy = existing_policy.copy()\n",
    "updated_policy[0]['Principal'].append(current_role_arn)\n",
    "updated_policy = str(updated_policy).replace(\"'\", '\"')\n",
    "\n",
    "response = opensearch_client.update_access_policy(\n",
    "    description='dataAccessPolicy',\n",
    "    name=data_access_policy_name,\n",
    "    policy=updated_policy,\n",
    "    policyVersion=policy_version,\n",
    "    type='data'\n",
    ")\n",
    "print(response)\n",
    "\n",
    "time.sleep(60) # Changes to the data access policy might take a bit to update\n",
    "\n",
    "# Set up AWS authentication\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "# Define index settings and mappings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": \"true\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                 \"method\": {\n",
    "                     \"name\": \"hnsw\",\n",
    "                     \"engine\": \"faiss\",\n",
    "                     \"space_type\": \"innerproduct\",\n",
    "                     \"parameters\": {\n",
    "                         \"ef_construction\": 512,\n",
    "                         \"m\": 16\n",
    "                     },\n",
    "                 },\n",
    "             },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"text-metadata\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build the OpenSearch client\n",
    "host = f\"{collection_id}.{region}.aoss.amazonaws.com\"\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{'host': host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Create index\n",
    "response = oss_client.indices.create(index=indexName, body=json.dumps(index_settings))\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff940dc9-0cc5-4fee-b6b8-d2765e739c00",
   "metadata": {},
   "source": [
    "#### Create the Knowledge Base\n",
    "In this section you will create the Knowledge Base. Before creating a new KB we need to define which embeddings model we want it to use. In this case we will be using Amazon Titan Embeddings V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58ca53-7d35-4650-a3c3-eb5258c13c22",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Amazon Titan Embeddings V2 access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf2f4c-ba74-431c-ac0e-8423713a2836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModelArn = \"arn:aws:bedrock:{}::foundation-model/amazon.titan-embed-text-v2:0\".format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeedd3a-214b-4bcb-a4cc-367eec74df17",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create our Knowledge Base for Amazon Bedrock. We have created an Amazon CloudFormation template which takes care of the configuration needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95056b8e-9584-43da-aa70-8dc58ee0c734",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4688cd2-3696-4d59-852e-9149e843f7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kb_id, datasource_id = create_kb_infrastructure(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71c3b4-aade-4a92-9d32-2af9ec27f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store kb_id datasource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01c1a7-402b-4d9b-9591-4725ddb02ce4",
   "metadata": {},
   "source": [
    "#### Sync the Knowledge Base\n",
    "As we have created and associated the data source to the Knowledge Base, we can proceed to Sync the data. \n",
    "\n",
    "\n",
    "Each time you add, modify, or remove files from the S3 bucket for a data source, you must sync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon Bedrock only processes the objects in your S3 bucket that have been added, modified, or deleted since the last sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4046cf-f821-4794-87ec-b0914f24d46b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingestion_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id,\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial Ingestion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3546d9-0a40-4b39-a899-0ae884fbca9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "    dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "    ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    ")[\"ingestionJob\"][\"status\"]\n",
    "print(status)\n",
    "while status not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "    status = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "        dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "        ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    "    )[\"ingestionJob\"][\"status\"]\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "print(\"Waiting for changes to take place in the vector database\")\n",
    "time.sleep(30) # Wait for all changes to take place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29291c-3b92-4f91-b8ec-46871e8ec9cf",
   "metadata": {},
   "source": [
    "#### Test the Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the **retrieve** and **retrieve_and_generate** APIs.\n",
    "\n",
    "Let's examine a test case with patient 0's transcript, where they mention a cat named Kelly. We'll query the knowledge base using the metadata filter for patient 0 to retrieve information about Kelly. Changing the patient_id will prevent the model from responding accurately. Read through the PDFs for other questions you might want to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87a85b-e706-4cd6-a80a-15bc707200ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this first example we are going to use the **retrieve and generate API**. This API queries a knowledge base and generates responses based on the retrieved results, using an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350a4a2-88c9-4493-982c-b15fd575519b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Anthropic Claude 3 Sonnet access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad84b5c-3fd5-4c45-a361-e26d02a7178a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve and generate API\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"Which office do I submit for golden eagle permits?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\".format(region),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5,\n",
    "                    \"filter\": {\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"corpus_id\",\n",
    "                            \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8276ab-10a5-477e-8ce4-d84b1a04a63d",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this second example we are going to use the **retrieve API**. This API queries the knowledge base and retrieves relavant information from it, it does not generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb520b34-f6c9-4caa-bd00-3c8d65c9745a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":3,\n",
    "            \"filter\": {\n",
    "                 \"equals\": {\n",
    "                    \"key\": \"corpus_id\",\n",
    "                    \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "    retrievalQuery={\n",
    "        'text': \"Which office do I submit for golden eagle permits?\"\n",
    "            \n",
    "        }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents\n",
    "# each list has content,location,score,metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912cc8b-de5f-44d8-810e-bfed78fbbfb3",
   "metadata": {},
   "source": [
    "If you are executing this notebook on SageMaker Studio you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<STUDIOID>>.studio.<<REGION>>.sagemaker.aws/jupyterlab/default/proxy/8501/\n",
    "```\n",
    "\n",
    "If you are executing this notebook on a SageMaker Notebook you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<NOTEBOOKID>>.notebook.<<REGION>>.sagemaker.aws/proxy/8501/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa127d7-307c-42d2-a126-be95a40098fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU opensearch-py streamlit streamlit-cognito-auth retrying boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac1baa-7bc5-4a74-8739-d4bf9f93bc8e",
   "metadata": {},
   "source": [
    "Let's import necessary Python modules and libraries, and initialize AWS service clients required for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0bc635ea-6e7f-4a4c-bf43-e0f6e0b3a5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import requests\n",
    "import random\n",
    "from utilsmod import create_base_infrastructure, create_kb_infrastructure, updateDataAccessPolicy, createAOSSIndex, replace_vars\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "lambda_client = boto3.client('lambda')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "cloudformation = boto3.client('cloudformation')\n",
    "opensearch = boto3.client('opensearchserverless')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock = boto3.client(\"bedrock\",region_name=region)\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "cognito_client = boto3.client('cognito-idp', region_name=region)\n",
    "identity_arn = session.client('sts').get_caller_identity()['Arn']\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "bucket_name = 'namer' + account_id + '-bucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b79b0-2ec3-44f9-a96e-3c7ac7057367",
   "metadata": {},
   "source": [
    "### 0. Base Infrastructure \n",
    "The following has already been created for you by the workshop: \n",
    "\n",
    "- Amazon Cognito User Pool and App Client. (user_pool_id, cognito_arn, client_id, client_secret)\n",
    "- Amazon DynamoDB Table\n",
    "- Amazon S3 Bucket\n",
    "- AWS Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe1f6b-1466-4e5a-b546-4db0b04f85f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f58007-9e40-414a-b95c-10ace181bbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "def short_uuid():\n",
    "    uuid_str = str(uuid.uuid4())\n",
    "    return uuid_str[:8]\n",
    "\n",
    "solution_id = 'KBS{}'.format(short_uuid()).lower()\n",
    "user_pool_id, user_pool_arn, cognito_arn, client_id, client_secret, dynamo_table, s3_bucket, lambda_function_arn, collection_id = create_base_infrastructure(solution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded437b-8dbd-4818-8099-010032a56aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE NO LONGER NEED THIS\n",
    "%store user_pool_id user_pool_arn cognito_arn client_id client_secret dynamo_table s3_bucket lambda_function_arn collection_id solution_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d3cb6-51d4-4616-bb44-fb6a91c99a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25d71a-c907-44ef-9846-2b0b98644ae5",
   "metadata": {},
   "source": [
    "### 1. Amazon Cognito User Pool: Users and Corpus\n",
    "#### Create users and corpus into the user pool\n",
    "We will create users and corpus to test out the use case. User ids are stored for later use when retrieving information.\n",
    "For the notebook to work you will need to replace the placeholder for 2 doctors and 3 patients. This users will be created in the Amazon Cognito user pool and you will later need them to log into the web application. While this is a dummy user creation for test purposes, in production use cases you will need to follow you organization best practices and guidelines to create users. \n",
    "\n",
    "**For this example, the first doctor will have associated the first two patients, and the second doctor will have associated the third patient.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7a8cf-4076-47d6-9ba1-91997a41c654",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> \n",
    "<br><b>Password minimum length:</b>8 character(s)\n",
    "<br><b>Password requirements</b>\n",
    "<br>Contains at least 1 number\n",
    "<br>Contains at least 1 special character\n",
    "<br>Contains at least 1 uppercase letter\n",
    "<br>Contains at least 1 lowercase letter\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e7d77-d7a8-4212-8684-c04eda9dbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "    {\n",
    "        'name': 'Highway Harry',\n",
    "        'email': 'highway.harry@acmecorp.com',\n",
    "        'password': 'Highway.Harry.123$',\n",
    "        'corpus': ['highway']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wildlife Walter',\n",
    "        'email': 'wildlife.walter@acmecorp.com',\n",
    "        'password': 'Wildlife.Walter.123$',\n",
    "        'corpus': ['wildlife']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Admin Amy',\n",
    "        'email': 'admin.amy@acmecorp.com',\n",
    "        'password': 'Admin.Amy.123$',\n",
    "        'corpus': ['highway', 'wildlife']\n",
    "    },\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    {\n",
    "        'name': 'highway',\n",
    "        'description': 'document regarding highway and roadsign regulations',\n",
    "        's3path': f\"s3://{s3_bucket}/highway/\"\n",
    "    },\n",
    "    {\n",
    "        'name': 'wildlife',\n",
    "        'description': 'documents regarding fishing and hunting regulations',\n",
    "        's3path': f's3://{s3_bucket}/wildlife/'\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513bd34d-70fb-4081-870b-132459cc6b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_ids = []\n",
    "corpus_ids = []\n",
    "\n",
    "def create_user(user_data, user_type):\n",
    "    user_ids = []\n",
    "    for user in user_data:\n",
    "        response = cognito_client.admin_create_user(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            UserAttributes=[\n",
    "                {'Name': 'name', 'Value': user['name']},\n",
    "                {'Name': 'email', 'Value': user['email']},\n",
    "                {'Name': 'email_verified', 'Value': 'true'}\n",
    "            ],\n",
    "            ForceAliasCreation=False,\n",
    "            MessageAction='SUPPRESS'\n",
    "        )\n",
    "        cognito_client.admin_set_user_password(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            Password=user['password'],\n",
    "            Permanent=True\n",
    "        )\n",
    "        print(f\"{user_type.capitalize()} created:\", response['User']['Username'])\n",
    "        print(f\"{user_type.capitalize()} id:\", response['User']['Attributes'][3]['Value'])\n",
    "        user_ids.append(response['User']['Attributes'][3]['Value'])\n",
    "    return user_ids\n",
    "\n",
    "user_ids = create_user(users, 'user')\n",
    "corpus_ids = [str(uuid.uuid4()) for c in corpus]\n",
    "\n",
    "print(\"User IDs:\", user_ids)\n",
    "print(\"Corpus IDs:\", corpus_ids)\n",
    "\n",
    "%store user_ids corpus_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e3118-526d-42d4-b34f-401790747159",
   "metadata": {},
   "source": [
    "### 2. User-corpus association in DynamoDB\n",
    "In this section we will populate the already created DynamoDB table with the user-corpus associations. This will be useful later on to retrieve the list of corpus ids a user is allowed to filter by. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977f654-201d-4ecf-afcb-a27cd021b2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = dynamodb_resource.Table(dynamo_table)\n",
    "corpus_mapping = [entry['name'] for entry in corpus]\n",
    "with table.batch_writer() as batch:\n",
    "    for corpus,user in enumerate(users):\n",
    "        temp = []\n",
    "        for corpus_id,corpuses in enumerate(corpus_mapping):\n",
    "            if corpuses in user['corpus']:\n",
    "                temp.append(corpus_ids[corpus_id])\n",
    "\n",
    "        batch.put_item(\n",
    "            Item={\n",
    "                'user_id': user_ids[corpus],\n",
    "                'corpus_id_list': temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "print('Data inserted successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7eec51df-791a-4fbb-827e-63b18ace58bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: source_transcripts/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf to s3://bucket_name/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf to s3://bucket_name/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/Loon - Wikipedia.pdf to s3://bucket_name/wildlife/Loon - Wikipedia.pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'namer' + account_id + '-bucket'\n",
    "!aws s3 cp ./source_transcripts/ s3://bucket_name/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e302f-c0d6-4312-b798-14390ffd9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the corpus and their corresponding IDs\n",
    "for corpuses, corpus_entry in enumerate(corpus):\n",
    "    corpus_id = corpus_ids[corpuses]\n",
    "    s3path = corpus_entry['s3path']\n",
    "    \n",
    "    # Get bucket and prefix\n",
    "    # Remove 's3://' and split bucket and prefix\n",
    "    path_parts = s3path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    prefix = path_parts[1] if len(path_parts) > 1 else ''\n",
    "    \n",
    "    # List all files in the S3 folder\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        files = [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    else:\n",
    "        files = []\n",
    "    \n",
    "    for file in files:\n",
    "        metadata = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"corpus_id\": corpus_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload metadata file to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key=f\"{file}.metadata.json\",\n",
    "            Body=json.dumps(metadata, indent=4),\n",
    "            ContentType='application/json'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30badb8-e804-4375-b5c0-7dd680f516b8",
   "metadata": {},
   "source": [
    "### 5. Upload to Amazon S3\n",
    "Knowledge Bases for Amazon Bedrock, currently require data to reside in an Amazon S3 bucket. We will upload both files and metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d72a8-d85f-4740-88b6-26557a57b72e",
   "metadata": {},
   "source": [
    "### 6. Create OpensearchServerless\n",
    "\n",
    "In this section we will create all the policies for the OpenSearch Serverless Collection and then create the collection itself.\n",
    "\n",
    "First we will create an encryption policy for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bf183fae-a0c7-4af8-b077-e014f151ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Rules\":[{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-431615879134-kbcollection\"]}], \"AWSOwnedKey\": true}\n",
      "{'securityPolicyDetail': {'createdDate': 1725552314705, 'description': 'Public encryption access namer workshop collection', 'lastModifiedDate': 1725552314705, 'name': 'namer-431615879134-kbenc', 'policy': {'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'ResourceType': 'collection'}], 'AWSOwnedKey': True}, 'policyVersion': 'MTcyNTU1MjMxNDcwNV8x', 'type': 'encryption'}, 'ResponseMetadata': {'RequestId': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'date': 'Thu, 05 Sep 2024 16:05:14 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '375', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '{{\"Rules\":[{{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-{0}-kbcollection\"]}}], \"AWSOwnedKey\": true}}'.format(account_id)\n",
    "print(policy)\n",
    "\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public encryption access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbenc',\n",
    "    policy=policy,\n",
    "    type='encryption'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f7e18-8b44-440b-baae-ac0d5286f4c2",
   "metadata": {},
   "source": [
    "Now we will create a Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e755390-6dbc-4537-a9a8-39895d753f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = opensearch.create_security_policy(\n",
    "    description='Public network access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbnet',\n",
    "    policy='''\"Rules\": [{[\"ResourceType\": \"dashboard\", \n",
    "    \"Resource\": [\"collection/namer-{0}-kbcollection\"]]}, \n",
    "    {{\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer{0}-kbcollection\"]}}], \n",
    "    \"AllowFromPublic\": true}}'''.format(account_id),\n",
    "    type='network'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a0d067-171a-41d6-a5e1-8bebf34d9daf",
   "metadata": {},
   "source": [
    "Next we need to create the Data Access Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7209ff-3ebd-410c-8169-588cafa4c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = opensearch.create_access_policy(\n",
    "    description='Data access policy for the NAMER summit',\n",
    "    name='namer-' + account_id + '-kbaccess',\n",
    "    policy='''[{\"Rules\": [{\"Resource\": [\"collection/namer-{0}-kbcollection\"], \n",
    "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
    "                           \"ResourceType\": \"collection\"}, \n",
    "                          {\"ResourceType\": \"index\", \"Resource\": [\"index/namer-{0}-kbcollection/*\"], \n",
    "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}], \n",
    "                \"Principal\": [\"arn:aws:iam::' + account_id + ':role/namer-{0}-kbrole\"]}]'''.format(account_id),\n",
    "    type='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ba3e9-ef23-45aa-8b50-5a8a7ce3cdec",
   "metadata": {},
   "source": [
    "### 7. Create a Knowledge Base for Amazon Bedrock\n",
    "\n",
    "In this section we will go through all the steps to create and test a Knowledge Base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8624ab7-0f43-4298-b708-71bf879f8b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexName = \"kb-acl-index-\" + solution_id\n",
    "print(\"Index name:\",indexName)\n",
    "%store indexName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80962f26-c080-4a85-9e14-8732b6f6074b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updateDataAccessPolicy(solution_id) # Adding the current role to the collection's data access policy\n",
    "time.sleep(60) # Changes to the data access policy might take a bit to update\n",
    "createAOSSIndex(indexName, region, collection_id) # Create the AOSS index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fec7a8-2cc0-4891-b33f-7e5b71e86396",
   "metadata": {},
   "source": [
    "#### Create the Knowledge Base\n",
    "In this section you will create the Knowledge Base. Before creating a new KB we need to define which embeddings model we want it to use. In this case we will be using Amazon Titan Embeddings V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc887613-68a2-475a-8ae4-19fae62414c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Amazon Titan Embeddings V2 access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c249e6-1ae6-4310-9e44-fd22b111536f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModelArn = \"arn:aws:bedrock:{}::foundation-model/amazon.titan-embed-text-v2:0\".format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a8498-a623-4ca3-ade5-3707be93c49d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create our Knowledge Base for Amazon Bedrock. We have created an Amazon CloudFormation template which takes care of the configuration needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d213c6-4814-4b6f-9c19-40a77e827dc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e685c-6dbb-4513-9abc-18e6ae5fd3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kb_id, datasource_id = create_kb_infrastructure(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f0e17-f5c6-4347-b537-73b84bb02811",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store kb_id datasource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1663852-4d79-443d-baa0-c43d8190eaac",
   "metadata": {},
   "source": [
    "#### Sync the Knowledge Base\n",
    "As we have created and associated the data source to the Knowledge Base, we can proceed to Sync the data. \n",
    "\n",
    "\n",
    "Each time you add, modify, or remove files from the S3 bucket for a data source, you must sync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon Bedrock only processes the objects in your S3 bucket that have been added, modified, or deleted since the last sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0eca1-a1df-48dd-b4d7-22a45e2be29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingestion_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id,\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial Ingestion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d161bd0-5e45-4c7f-95ea-305e57bd9cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "    dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "    ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    ")[\"ingestionJob\"][\"status\"]\n",
    "print(status)\n",
    "while status not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "    status = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "        dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "        ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    "    )[\"ingestionJob\"][\"status\"]\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "print(\"Waiting for changes to take place in the vector database\")\n",
    "time.sleep(30) # Wait for all changes to take place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868477cf-425d-4810-b25a-518eab5c22c5",
   "metadata": {},
   "source": [
    "#### Test the Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the **retrieve** and **retrieve_and_generate** APIs.\n",
    "\n",
    "Let's examine a test case with patient 0's transcript, where they mention a cat named Kelly. We'll query the knowledge base using the metadata filter for patient 0 to retrieve information about Kelly. Changing the patient_id will prevent the model from responding accurately. Read through the PDFs for other questions you might want to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462c802-9f57-426c-b610-4db77c844891",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this first example we are going to use the **retrieve and generate API**. This API queries a knowledge base and generates responses based on the retrieved results, using an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0827d4-88a2-4f08-8ef1-23af9d455c05",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Anthropic Claude 3 Sonnet access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67811b25-2fc1-4730-aa16-36b5e53b6aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve and generate API\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"Which office do I submit for golden eagle permits?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\".format(region),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5,\n",
    "                    \"filter\": {\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"corpus_id\",\n",
    "                            \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93c1a5-0ba4-4f99-9db8-4ad7be3cab7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this second example we are going to use the **retrieve API**. This API queries the knowledge base and retrieves relavant information from it, it does not generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988de2b1-4a9f-441a-933a-3f1ea97365a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":3,\n",
    "            \"filter\": {\n",
    "                 \"equals\": {\n",
    "                    \"key\": \"corpus_id\",\n",
    "                    \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "    retrievalQuery={\n",
    "        'text': \"Which office do I submit for golden eagle permits?\"\n",
    "            \n",
    "        }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents\n",
    "# each list has content,location,score,metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad65e10-3bad-4ca9-8009-8f85ed91f92e",
   "metadata": {},
   "source": [
    "### 7. Add Lambda Layer\n",
    "At the time of developing this notebook, the latest Boto3 version available in Lambda with Python 3.12 does not include metadata filtering capabilities. To solve this, we will create and attach an AWS Lambda Layer with the latest Boto3 version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428607b-0a0d-4efa-8bdd-dd29c63abc9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this section to run you will need the **zip** package to by installed at the system level.\n",
    "\n",
    "You can check if zip is installed running the following command: !zip\n",
    "\n",
    "If it is not installed you will need to install it using the appropriate package manager (apt-get for Debian-based systems or yum for RHEL-based systems for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c3644-09c3-4b11-aac9-2732204572f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we have the lambda layer already attached to the lambda function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68603d37-7e37-41c4-aa37-6997f680111f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!zip\n",
    "!sudo apt-get install zip -y # Debian-based systems \n",
    "#!sudo yum install zip -y # RHEL-based systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2126d9-7fe1-421c-879e-447ca4a1915d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir latest-sdk-layer\n",
    "%cd latest-sdk-layer\n",
    "!pip install -qU boto3 botocore -t python/lib/python3.12/site-packages/\n",
    "!zip -rq latest-sdk-layer.zip .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4894d13-7b90-40fc-96d2-de517574ff49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes):\n",
    "    with open(zip_file_path, 'rb') as f:\n",
    "        response = lambda_client.publish_layer_version(\n",
    "            LayerName=layer_name,\n",
    "            Description=description,\n",
    "            Content={\n",
    "                'ZipFile': f.read(),\n",
    "            },\n",
    "            CompatibleRuntimes=compatible_runtimes\n",
    "        )\n",
    "    return response['LayerVersionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171637fa-5671-44a3-be06-1f3400ec8fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_name = 'latest-sdk-layer'\n",
    "description = 'Layer with the latest boto3 version.'\n",
    "zip_file_path = 'latest-sdk-layer/latest-sdk-layer.zip'\n",
    "compatible_runtimes = ['python3.12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2e5c7-a29a-4d20-bd49-c6df4b605a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_version_arn = publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes)\n",
    "print(\"Layer version ARN:\", layer_version_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea5300-419a-4641-b4e8-453f434220a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Add the layer to the Lambda function\n",
    "    lambda_client.update_function_configuration(\n",
    "        FunctionName=lambda_function_arn,\n",
    "        Layers=[layer_version_arn]\n",
    "    )\n",
    "    print(\"Layer added to the Lambda function successfully.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    print(f\"Error adding layer to Lambda function: {e.response['Error']['Message']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db5760a-f8e6-4ec6-852a-273afa467dfe",
   "metadata": {},
   "source": [
    "### 8. Create Streamlit Application\n",
    "To showcase the interaction between doctors and the Knowledge Bases, we can develop a user-friendly web application using Streamlit for testing purposes, a popular open-source Python library for building interactive data apps. Streamlit provides a simple and intuitive way to create custom interfaces that can seamlessly integrate with the various AWS services involved in this solution.\n",
    "\n",
    "Here is the application, **don't modify the placeholders, we will replace them in the next cell.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a1b06-6fb0-4c36-a0b0-27319413d8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import streamlit as st\n",
    "from streamlit_cognito_auth import CognitoAuthenticator\n",
    "\n",
    "pool_id = \"<<replace_pool_id>>\"\n",
    "app_client_id = \"<<replace_app_client_id>>\"\n",
    "app_client_secret = \"<<replace_app_client_secret>>\"\n",
    "kb_id = \"<<replace_kb_id>>\"\n",
    "lambda_function_arn = '<<replace_lambda_function_arn>>'\n",
    "dynamo_table = '<<replace_dynamo_table_name>>'\n",
    "\n",
    "authenticator = CognitoAuthenticator(\n",
    "    pool_id=pool_id,\n",
    "    app_client_id=app_client_id,\n",
    "    app_client_secret= app_client_secret,\n",
    "    use_cookies=False\n",
    ")\n",
    "\n",
    "is_logged_in = authenticator.login()\n",
    "\n",
    "if not is_logged_in:\n",
    "    st.stop()\n",
    "\n",
    "def logout():\n",
    "    authenticator.logout()\n",
    "\n",
    "def get_user_sub(user_pool_id, username):\n",
    "    cognito_client = boto3.client('cognito-idp')\n",
    "    try:\n",
    "        response = cognito_client.admin_get_user(\n",
    "            UserPoolId=pool_id,\n",
    "            Username=authenticator.get_username()\n",
    "        )\n",
    "        sub = None\n",
    "        for attr in response['UserAttributes']:\n",
    "            if attr['Name'] == 'sub':\n",
    "                sub = attr['Value']\n",
    "                break\n",
    "        return sub\n",
    "    except cognito_client.exceptions.UserNotFoundException:\n",
    "        print(\"User not found.\")\n",
    "        return None\n",
    "\n",
    "def get_corpus_ids(user_id):\n",
    "    dynamodb = boto3.client('dynamodb')\n",
    "    response = dynamodb.query(\n",
    "        TableName=dynamo_table,\n",
    "        KeyConditionExpression='user_id = :user_id',\n",
    "        ExpressionAttributeValues={\n",
    "            ':user_id': {'S': user_id}\n",
    "        }\n",
    "    )\n",
    "    print(response)\n",
    "    corpus_id_list = []  # Initialize the list\n",
    "    for item in response['Items']:\n",
    "        corpus_ids = item.get('corpus_id_list', {}).get('L', [])\n",
    "        corpus_id_list.extend([corpus_id['S'] for corpus_id in corpus_ids])\n",
    "    return corpus_id_list\n",
    "\n",
    "def search_transcript(user_id, kb_id, text, corpus_ids):\n",
    "    # Initialize the Lambda client\n",
    "    lambda_client = boto3.client('lambda')\n",
    "\n",
    "    # Payload for the Lambda function\n",
    "    payload = json.dumps({\n",
    "        \"userId\": sub,\n",
    "        \"knowledgeBaseId\": kb_id,\n",
    "        \"text\": text, \n",
    "        \"corpusIds\": corpus_ids\n",
    "    }).encode('utf-8')\n",
    "\n",
    "    try:\n",
    "        # Invoke the Lambda function\n",
    "        response = lambda_client.invoke(\n",
    "            FunctionName=lambda_function_arn,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=payload\n",
    "        )\n",
    "\n",
    "        # Process the response\n",
    "        if response['StatusCode'] == 200:\n",
    "            response_payload = json.loads(response['Payload'].read().decode('utf-8'))\n",
    "            return response_payload\n",
    "        else:\n",
    "            # Handle error response\n",
    "            return {'error': 'Failed to fetch data'}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exception\n",
    "        return {'error': str(e)}\n",
    "\n",
    "sub = get_user_sub(pool_id, authenticator.get_username())\n",
    "print(sub)\n",
    "corpus_ids = get_corpus_ids(sub)\n",
    "print(corpus_ids)\n",
    "\n",
    "# Application Front\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"User Information\")\n",
    "    st.markdown(\"## User\")\n",
    "    st.text(authenticator.get_username())\n",
    "    st.markdown(\"## User Id\")\n",
    "    st.text(sub)\n",
    "    # selected_patient = st.selectbox(\"Select a patient (or 'All' for all patients)\", ['All'] + patient_ids)\n",
    "    st.button(\"Logout\", \"logout_btn\", on_click=logout)\n",
    "\n",
    "st.header(\"Corpus Search Tool\")\n",
    "\n",
    "# Text input for the search query\n",
    "query = st.text_input(\"Enter your search query:\")\n",
    "\n",
    "if st.button(\"Search\"):\n",
    "    if query:\n",
    "        # Perform search\n",
    "        corpus_ids_filter = corpus_ids\n",
    "        results = search_transcript(sub, kb_id, query, corpus_ids_filter)\n",
    "        print(results)\n",
    "        if results:\n",
    "            st.subheader(\"Search Results:\")\n",
    "            st.markdown(results[\"body\"], unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(\"No matching results found in corpus.\")\n",
    "    else:\n",
    "        st.write(\"Please enter a search query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b58f02-bfa7-4c8f-80cb-f47c10ad1c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_vars(\"app.py\", user_pool_id, client_id, client_secret, kb_id, lambda_function_arn, dynamo_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4af76d-428f-45df-b082-6f8b2ab15723",
   "metadata": {},
   "source": [
    "#### Execute the streamlit locally\n",
    "Execute the cell below to run the Streamlit application.\n",
    "\n",
    "**Use the email and password of the doctors you defined at the top of the notebook to access the application.**\n",
    "\n",
    "Once you have logged in, you can filter by specific patients you have assigned (dropdown in the left panel), or all to query the knowledge base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a6b85-af35-4283-95fb-eae1c62e9f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd734a82-46cf-48fc-b7fc-a28532b6fd5c",
   "metadata": {},
   "source": [
    "If you are executing this notebook on SageMaker Studio you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<STUDIOID>>.studio.<<REGION>>.sagemaker.aws/jupyterlab/default/proxy/8501/\n",
    "```\n",
    "\n",
    "If you are executing this notebook on a SageMaker Notebook you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<NOTEBOOKID>>.notebook.<<REGION>>.sagemaker.aws/proxy/8501/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1802e91-1826-4399-a3c2-34b787887c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://rxhmevhu84g12we.studio.us-west-2.sagemaker.aws/jupyterlab/default/proxy/8501/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77585073-6684-4662-a78f-20e2d43a7c6f",
   "metadata": {},
   "source": [
    "### 9. Clean up\n",
    "**Before running this cell you will need to stop the cell above where the app is runnning!**\n",
    "\n",
    "Run the following cell to delete the created resources and avoid unnecesary costs. This should take about 2-3 minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ccc8b-a828-416f-9c93-9482c929f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete all objects in the bucket\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=s3_bucket)\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            s3_client.delete_object(Bucket=s3_bucket, Key=obj['Key'])\n",
    "        print(f\"All objects in {s3_bucket} have been deleted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting objects from {s3_bucket}: {e}\")\n",
    "\n",
    "# Define the stack names to delete\n",
    "stack_names = [\"KB-E2E-KB-{}\".format(solution_id),\"KB-E2E-Base-{}\".format(solution_id)]\n",
    "\n",
    "# Iterate over the stack names and delete each stack\n",
    "for stack_name in stack_names:\n",
    "    try:\n",
    "        # Retrieve the stack information\n",
    "        stack_info = cloudformation.describe_stacks(StackName=stack_name)\n",
    "        stack_status = stack_info['Stacks'][0]['StackStatus']\n",
    "\n",
    "        # Check if the stack exists and is in a deletable state\n",
    "        if stack_status != 'DELETE_COMPLETE':\n",
    "            # Delete the stack\n",
    "            cloudformation.delete_stack(StackName=stack_name)\n",
    "            print(f'Deleting stack: {stack_name}')\n",
    "\n",
    "            # Wait for the stack deletion to complete\n",
    "            waiter = cloudformation.get_waiter('stack_delete_complete')\n",
    "            waiter.wait(StackName=stack_name)\n",
    "            print(f'Stack {stack_name} deleted successfully.')\n",
    "        else:\n",
    "            print(f'Stack {stack_name} does not exist or has already been deleted.')\n",
    "\n",
    "    except cloudformation.exceptions.ClientError as e:\n",
    "        print(f'Error deleting stack {stack_name}: {e.response[\"Error\"][\"Message\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d987d46-c21a-41e0-bd94-b3b44efb74af",
   "metadata": {},
   "source": [
    "### 2. User-corpus association in DynamoDB\n",
    "In this section we will populate the already created DynamoDB table with the user-corpus associations. This will be useful later on to retrieve the list of corpus ids a user is allowed to filter by. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4848a-433f-454e-8525-dcf742c06ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = dynamodb_resource.Table(dynamo_table)\n",
    "corpus_mapping = [entry['name'] for entry in corpus]\n",
    "with table.batch_writer() as batch:\n",
    "    for corpus,user in enumerate(users):\n",
    "        temp = []\n",
    "        for corpus_id,corpuses in enumerate(corpus_mapping):\n",
    "            if corpuses in user['corpus']:\n",
    "                temp.append(corpus_ids[corpus_id])\n",
    "\n",
    "        batch.put_item(\n",
    "            Item={\n",
    "                'user_id': user_ids[corpus],\n",
    "                'corpus_id_list': temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "print('Data inserted successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fb0f5030-e739-4dd5-abc5-ced3dddc7b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload failed: source_transcripts/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf to s3://bucket_name/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf to s3://bucket_name/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n",
      "upload failed: source_transcripts/wildlife/Loon - Wikipedia.pdf to s3://bucket_name/wildlife/Loon - Wikipedia.pdf An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'namer' + account_id + '-bucket'\n",
    "!aws s3 cp ./source_transcripts/ s3://bucket_name/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef979b-f7c4-4510-81fa-844436ca2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the corpus and their corresponding IDs\n",
    "for corpuses, corpus_entry in enumerate(corpus):\n",
    "    corpus_id = corpus_ids[corpuses]\n",
    "    s3path = corpus_entry['s3path']\n",
    "    \n",
    "    # Get bucket and prefix\n",
    "    # Remove 's3://' and split bucket and prefix\n",
    "    path_parts = s3path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    prefix = path_parts[1] if len(path_parts) > 1 else ''\n",
    "    \n",
    "    # List all files in the S3 folder\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        files = [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    else:\n",
    "        files = []\n",
    "    \n",
    "    for file in files:\n",
    "        metadata = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"corpus_id\": corpus_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload metadata file to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key=f\"{file}.metadata.json\",\n",
    "            Body=json.dumps(metadata, indent=4),\n",
    "            ContentType='application/json'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb8c1b-6113-43e3-b201-0fdd4a17d68d",
   "metadata": {},
   "source": [
    "### 5. Upload to Amazon S3\n",
    "Knowledge Bases for Amazon Bedrock, currently require data to reside in an Amazon S3 bucket. We will upload both files and metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035c3e3-fe23-4bee-a5b1-2c29ebdd2b87",
   "metadata": {},
   "source": [
    "### 6. Create OpensearchServerless\n",
    "\n",
    "In this section we will create all the policies for the OpenSearch Serverless Collection and then create the collection itself.\n",
    "\n",
    "First we will create an encryption policy for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6c52d539-ace0-47bb-a606-f6bfc687ac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Rules\":[{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-431615879134-kbcollection\"]}], \"AWSOwnedKey\": true}\n",
      "{'securityPolicyDetail': {'createdDate': 1725552314705, 'description': 'Public encryption access namer workshop collection', 'lastModifiedDate': 1725552314705, 'name': 'namer-431615879134-kbenc', 'policy': {'Rules': [{'Resource': ['collection/namer-431615879134-kbcollection'], 'ResourceType': 'collection'}], 'AWSOwnedKey': True}, 'policyVersion': 'MTcyNTU1MjMxNDcwNV8x', 'type': 'encryption'}, 'ResponseMetadata': {'RequestId': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '08c8dd23-67d8-4889-b740-a393a0e3ed18', 'date': 'Thu, 05 Sep 2024 16:05:14 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '375', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "policy = '{{\"Rules\":[{{\"ResourceType\": \"collection\", \"Resource\":[\"collection/namer-{0}-kbcollection\"]}}], \"AWSOwnedKey\": true}}'.format(account_id)\n",
    "print(policy)\n",
    "\n",
    "results = opensearch.create_security_policy(\n",
    "    description='Public encryption access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbenc',\n",
    "    policy=policy,\n",
    "    type='encryption'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e47190-8995-4475-a161-4c2e70ee49af",
   "metadata": {},
   "source": [
    "Now we will create a Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d370430-8a83-4edb-9e23-a1bcd46681f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = opensearch.create_security_policy(\n",
    "    description='Public network access namer workshop collection',\n",
    "    name='namer-' + account_id + '-kbnet',\n",
    "    policy='''\"Rules\": [{[\"ResourceType\": \"dashboard\", \n",
    "    \"Resource\": [\"collection/namer-{0}-kbcollection\"]]}, \n",
    "    {{\"ResourceType\": \"collection\", \"Resource\": [\"collection/namer{0}-kbcollection\"]}}], \n",
    "    \"AllowFromPublic\": true}}'''.format(account_id),\n",
    "    type='network'\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71853ea-4be8-407f-a99a-7e87b77230d3",
   "metadata": {},
   "source": [
    "Next we need to create the Data Access Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35776973-6633-478b-8c72-2fe8ed184afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = opensearch.create_access_policy(\n",
    "    description='Data access policy for the NAMER summit',\n",
    "    name='namer-' + account_id + '-kbaccess',\n",
    "    policy='''[{\"Rules\": [{\"Resource\": [\"collection/namer-{0}-kbcollection\"], \n",
    "                           \"Permission\": [\"aoss:CreateCollectionItems\", \"aoss:UpdateCollectionItems\", \"aoss:DescribeCollectionItems\"], \n",
    "                           \"ResourceType\": \"collection\"}, \n",
    "                          {\"ResourceType\": \"index\", \"Resource\": [\"index/namer-{0}-kbcollection/*\"], \n",
    "                           \"Permission\": [\"aoss:CreateIndex\", \"aoss:DescribeIndex\", \"aoss:ReadDocument\", \"aoss:WriteDocument\", \"aoss:UpdateIndex\", \"aoss:DeleteIndex\"]}], \n",
    "                \"Principal\": [\"arn:aws:iam::' + account_id + ':role/namer-{0}-kbrole\"]}]'''.format(account_id),\n",
    "    type='data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dc4c3-ce88-4499-b751-5706338bf5d1",
   "metadata": {},
   "source": [
    "### 7. Create a Knowledge Base for Amazon Bedrock\n",
    "\n",
    "In this section we will go through all the steps to create and test a Knowledge Base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571aff17-80e6-4d7f-913f-ccc879786c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexName = \"kb-acl-index-\" + solution_id\n",
    "print(\"Index name:\",indexName)\n",
    "%store indexName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339570da-950a-4d58-a888-e185799623a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updateDataAccessPolicy(solution_id) # Adding the current role to the collection's data access policy\n",
    "time.sleep(60) # Changes to the data access policy might take a bit to update\n",
    "createAOSSIndex(indexName, region, collection_id) # Create the AOSS index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee99bc2-9f8c-4b1d-9458-27b63738a2b7",
   "metadata": {},
   "source": [
    "#### Create the Knowledge Base\n",
    "In this section you will create the Knowledge Base. Before creating a new KB we need to define which embeddings model we want it to use. In this case we will be using Amazon Titan Embeddings V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd94730-3623-4000-af2a-16758f108ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Amazon Titan Embeddings V2 access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeac2ba-9a16-4890-bed7-40e1b2eaa460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModelArn = \"arn:aws:bedrock:{}::foundation-model/amazon.titan-embed-text-v2:0\".format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5c8db-1f89-416b-978d-f5d2772eb2ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create our Knowledge Base for Amazon Bedrock. We have created an Amazon CloudFormation template which takes care of the configuration needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403df85-5155-4491-9ced-e4d434fca95c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413252cf-2c6f-408d-b91f-4aa9b2e4d441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kb_id, datasource_id = create_kb_infrastructure(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2add11-1275-4077-b766-4589cec5bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store kb_id datasource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac914ad-8e49-42b5-b1b6-4ff717ca673c",
   "metadata": {},
   "source": [
    "#### Sync the Knowledge Base\n",
    "As we have created and associated the data source to the Knowledge Base, we can proceed to Sync the data. \n",
    "\n",
    "\n",
    "Each time you add, modify, or remove files from the S3 bucket for a data source, you must sync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon Bedrock only processes the objects in your S3 bucket that have been added, modified, or deleted since the last sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866b11b-981c-457a-a33e-5eab7868b79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingestion_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id,\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial Ingestion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d4611-ab50-4823-b495-ba30062b862f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "    dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "    ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    ")[\"ingestionJob\"][\"status\"]\n",
    "print(status)\n",
    "while status not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "    status = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "        dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "        ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    "    )[\"ingestionJob\"][\"status\"]\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "print(\"Waiting for changes to take place in the vector database\")\n",
    "time.sleep(30) # Wait for all changes to take place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba5f42-4501-412b-99fa-4cad85836ed6",
   "metadata": {},
   "source": [
    "#### Test the Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the **retrieve** and **retrieve_and_generate** APIs.\n",
    "\n",
    "Let's examine a test case with patient 0's transcript, where they mention a cat named Kelly. We'll query the knowledge base using the metadata filter for patient 0 to retrieve information about Kelly. Changing the patient_id will prevent the model from responding accurately. Read through the PDFs for other questions you might want to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581f71a-dfd2-466f-877a-d55cbbd7b4ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this first example we are going to use the **retrieve and generate API**. This API queries a knowledge base and generates responses based on the retrieved results, using an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2a976-eaad-4376-9d28-d64eef0cddfa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Anthropic Claude 3 Sonnet access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e50e3e-bccd-492b-bc58-61771e3f6e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve and generate API\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"Which office do I submit for golden eagle permits?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\".format(region),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5,\n",
    "                    \"filter\": {\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"corpus_id\",\n",
    "                            \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee57d5-aa05-4960-b6f0-37b63c40dc95",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this second example we are going to use the **retrieve API**. This API queries the knowledge base and retrieves relavant information from it, it does not generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813007b2-89b2-4ea5-a659-900e3cb5b652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":3,\n",
    "            \"filter\": {\n",
    "                 \"equals\": {\n",
    "                    \"key\": \"corpus_id\",\n",
    "                    \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "    retrievalQuery={\n",
    "        'text': \"Which office do I submit for golden eagle permits?\"\n",
    "            \n",
    "        }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents\n",
    "# each list has content,location,score,metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d423c1d-6f4e-475c-a9df-aca4e260f1ad",
   "metadata": {},
   "source": [
    "### 7. Add Lambda Layer\n",
    "At the time of developing this notebook, the latest Boto3 version available in Lambda with Python 3.12 does not include metadata filtering capabilities. To solve this, we will create and attach an AWS Lambda Layer with the latest Boto3 version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae75622-c2c4-4254-97fc-344cfb2f9d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this section to run you will need the **zip** package to by installed at the system level.\n",
    "\n",
    "You can check if zip is installed running the following command: !zip\n",
    "\n",
    "If it is not installed you will need to install it using the appropriate package manager (apt-get for Debian-based systems or yum for RHEL-based systems for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092ab7e-9085-4a80-abca-574d86896969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we have the lambda layer already attached to the lambda function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f7147-d1e6-4398-805c-ebc0fe4dcbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!zip\n",
    "!sudo apt-get install zip -y # Debian-based systems \n",
    "#!sudo yum install zip -y # RHEL-based systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9a4d6-9f6a-4ea9-b4fe-f3780e1b9f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir latest-sdk-layer\n",
    "%cd latest-sdk-layer\n",
    "!pip install -qU boto3 botocore -t python/lib/python3.12/site-packages/\n",
    "!zip -rq latest-sdk-layer.zip .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ba738-0189-4a90-89ec-b9b943b76321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes):\n",
    "    with open(zip_file_path, 'rb') as f:\n",
    "        response = lambda_client.publish_layer_version(\n",
    "            LayerName=layer_name,\n",
    "            Description=description,\n",
    "            Content={\n",
    "                'ZipFile': f.read(),\n",
    "            },\n",
    "            CompatibleRuntimes=compatible_runtimes\n",
    "        )\n",
    "    return response['LayerVersionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98310bc3-0e55-4fa1-91d4-18be392f2d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_name = 'latest-sdk-layer'\n",
    "description = 'Layer with the latest boto3 version.'\n",
    "zip_file_path = 'latest-sdk-layer/latest-sdk-layer.zip'\n",
    "compatible_runtimes = ['python3.12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dedb562-aeac-4d4a-8997-1d9ad80aa44b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_version_arn = publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes)\n",
    "print(\"Layer version ARN:\", layer_version_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36358e-fa07-4fd8-943a-c46fc75bd8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Add the layer to the Lambda function\n",
    "    lambda_client.update_function_configuration(\n",
    "        FunctionName=lambda_function_arn,\n",
    "        Layers=[layer_version_arn]\n",
    "    )\n",
    "    print(\"Layer added to the Lambda function successfully.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    print(f\"Error adding layer to Lambda function: {e.response['Error']['Message']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de363cac-4c19-4f86-a637-da1d966578db",
   "metadata": {},
   "source": [
    "### 8. Create Streamlit Application\n",
    "To showcase the interaction between doctors and the Knowledge Bases, we can develop a user-friendly web application using Streamlit for testing purposes, a popular open-source Python library for building interactive data apps. Streamlit provides a simple and intuitive way to create custom interfaces that can seamlessly integrate with the various AWS services involved in this solution.\n",
    "\n",
    "Here is the application, **don't modify the placeholders, we will replace them in the next cell.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da093c-c3b1-4d8f-94e1-c1ae6811b65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import streamlit as st\n",
    "from streamlit_cognito_auth import CognitoAuthenticator\n",
    "\n",
    "pool_id = \"<<replace_pool_id>>\"\n",
    "app_client_id = \"<<replace_app_client_id>>\"\n",
    "app_client_secret = \"<<replace_app_client_secret>>\"\n",
    "kb_id = \"<<replace_kb_id>>\"\n",
    "lambda_function_arn = '<<replace_lambda_function_arn>>'\n",
    "dynamo_table = '<<replace_dynamo_table_name>>'\n",
    "\n",
    "authenticator = CognitoAuthenticator(\n",
    "    pool_id=pool_id,\n",
    "    app_client_id=app_client_id,\n",
    "    app_client_secret= app_client_secret,\n",
    "    use_cookies=False\n",
    ")\n",
    "\n",
    "is_logged_in = authenticator.login()\n",
    "\n",
    "if not is_logged_in:\n",
    "    st.stop()\n",
    "\n",
    "def logout():\n",
    "    authenticator.logout()\n",
    "\n",
    "def get_user_sub(user_pool_id, username):\n",
    "    cognito_client = boto3.client('cognito-idp')\n",
    "    try:\n",
    "        response = cognito_client.admin_get_user(\n",
    "            UserPoolId=pool_id,\n",
    "            Username=authenticator.get_username()\n",
    "        )\n",
    "        sub = None\n",
    "        for attr in response['UserAttributes']:\n",
    "            if attr['Name'] == 'sub':\n",
    "                sub = attr['Value']\n",
    "                break\n",
    "        return sub\n",
    "    except cognito_client.exceptions.UserNotFoundException:\n",
    "        print(\"User not found.\")\n",
    "        return None\n",
    "\n",
    "def get_corpus_ids(user_id):\n",
    "    dynamodb = boto3.client('dynamodb')\n",
    "    response = dynamodb.query(\n",
    "        TableName=dynamo_table,\n",
    "        KeyConditionExpression='user_id = :user_id',\n",
    "        ExpressionAttributeValues={\n",
    "            ':user_id': {'S': user_id}\n",
    "        }\n",
    "    )\n",
    "    print(response)\n",
    "    corpus_id_list = []  # Initialize the list\n",
    "    for item in response['Items']:\n",
    "        corpus_ids = item.get('corpus_id_list', {}).get('L', [])\n",
    "        corpus_id_list.extend([corpus_id['S'] for corpus_id in corpus_ids])\n",
    "    return corpus_id_list\n",
    "\n",
    "def search_transcript(user_id, kb_id, text, corpus_ids):\n",
    "    # Initialize the Lambda client\n",
    "    lambda_client = boto3.client('lambda')\n",
    "\n",
    "    # Payload for the Lambda function\n",
    "    payload = json.dumps({\n",
    "        \"userId\": sub,\n",
    "        \"knowledgeBaseId\": kb_id,\n",
    "        \"text\": text, \n",
    "        \"corpusIds\": corpus_ids\n",
    "    }).encode('utf-8')\n",
    "\n",
    "    try:\n",
    "        # Invoke the Lambda function\n",
    "        response = lambda_client.invoke(\n",
    "            FunctionName=lambda_function_arn,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=payload\n",
    "        )\n",
    "\n",
    "        # Process the response\n",
    "        if response['StatusCode'] == 200:\n",
    "            response_payload = json.loads(response['Payload'].read().decode('utf-8'))\n",
    "            return response_payload\n",
    "        else:\n",
    "            # Handle error response\n",
    "            return {'error': 'Failed to fetch data'}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exception\n",
    "        return {'error': str(e)}\n",
    "\n",
    "sub = get_user_sub(pool_id, authenticator.get_username())\n",
    "print(sub)\n",
    "corpus_ids = get_corpus_ids(sub)\n",
    "print(corpus_ids)\n",
    "\n",
    "# Application Front\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"User Information\")\n",
    "    st.markdown(\"## User\")\n",
    "    st.text(authenticator.get_username())\n",
    "    st.markdown(\"## User Id\")\n",
    "    st.text(sub)\n",
    "    # selected_patient = st.selectbox(\"Select a patient (or 'All' for all patients)\", ['All'] + patient_ids)\n",
    "    st.button(\"Logout\", \"logout_btn\", on_click=logout)\n",
    "\n",
    "st.header(\"Corpus Search Tool\")\n",
    "\n",
    "# Text input for the search query\n",
    "query = st.text_input(\"Enter your search query:\")\n",
    "\n",
    "if st.button(\"Search\"):\n",
    "    if query:\n",
    "        # Perform search\n",
    "        corpus_ids_filter = corpus_ids\n",
    "        results = search_transcript(sub, kb_id, query, corpus_ids_filter)\n",
    "        print(results)\n",
    "        if results:\n",
    "            st.subheader(\"Search Results:\")\n",
    "            st.markdown(results[\"body\"], unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(\"No matching results found in corpus.\")\n",
    "    else:\n",
    "        st.write(\"Please enter a search query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d77105-f1c9-4ba5-a066-4cb00220ccc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_vars(\"app.py\", user_pool_id, client_id, client_secret, kb_id, lambda_function_arn, dynamo_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeed552-af3a-4f0f-b12d-d38c809164fc",
   "metadata": {},
   "source": [
    "#### Execute the streamlit locally\n",
    "Execute the cell below to run the Streamlit application.\n",
    "\n",
    "**Use the email and password of the doctors you defined at the top of the notebook to access the application.**\n",
    "\n",
    "Once you have logged in, you can filter by specific patients you have assigned (dropdown in the left panel), or all to query the knowledge base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb48ce1-369f-41c8-b3a9-7661ff02c3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984020c-9b64-450e-a106-b78c2f19586d",
   "metadata": {},
   "source": [
    "If you are executing this notebook on SageMaker Studio you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<STUDIOID>>.studio.<<REGION>>.sagemaker.aws/jupyterlab/default/proxy/8501/\n",
    "```\n",
    "\n",
    "If you are executing this notebook on a SageMaker Notebook you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<NOTEBOOKID>>.notebook.<<REGION>>.sagemaker.aws/proxy/8501/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f77deb-48d8-4c86-9b77-e17329dd252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://rxhmevhu84g12we.studio.us-west-2.sagemaker.aws/jupyterlab/default/proxy/8501/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f4878-6bcb-4455-a59c-133b207bc1d1",
   "metadata": {},
   "source": [
    "### 9. Clean up\n",
    "**Before running this cell you will need to stop the cell above where the app is runnning!**\n",
    "\n",
    "Run the following cell to delete the created resources and avoid unnecesary costs. This should take about 2-3 minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f28a6-d948-4c0a-88c2-9601d5ed084f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete all objects in the bucket\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=s3_bucket)\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            s3_client.delete_object(Bucket=s3_bucket, Key=obj['Key'])\n",
    "        print(f\"All objects in {s3_bucket} have been deleted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting objects from {s3_bucket}: {e}\")\n",
    "\n",
    "# Define the stack names to delete\n",
    "stack_names = [\"KB-E2E-KB-{}\".format(solution_id),\"KB-E2E-Base-{}\".format(solution_id)]\n",
    "\n",
    "# Iterate over the stack names and delete each stack\n",
    "for stack_name in stack_names:\n",
    "    try:\n",
    "        # Retrieve the stack information\n",
    "        stack_info = cloudformation.describe_stacks(StackName=stack_name)\n",
    "        stack_status = stack_info['Stacks'][0]['StackStatus']\n",
    "\n",
    "        # Check if the stack exists and is in a deletable state\n",
    "        if stack_status != 'DELETE_COMPLETE':\n",
    "            # Delete the stack\n",
    "            cloudformation.delete_stack(StackName=stack_name)\n",
    "            print(f'Deleting stack: {stack_name}')\n",
    "\n",
    "            # Wait for the stack deletion to complete\n",
    "            waiter = cloudformation.get_waiter('stack_delete_complete')\n",
    "            waiter.wait(StackName=stack_name)\n",
    "            print(f'Stack {stack_name} deleted successfully.')\n",
    "        else:\n",
    "            print(f'Stack {stack_name} does not exist or has already been deleted.')\n",
    "\n",
    "    except cloudformation.exceptions.ClientError as e:\n",
    "        print(f'Error deleting stack {stack_name}: {e.response[\"Error\"][\"Message\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
