{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fd75d5-95e0-4079-9b99-fdb796f9b4f4",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock\n",
    "## Access Control Filtering - End to end notebook\n",
    "\n",
    "This notebook will guide the users on creating access controls for Knowledge Bases on Amazon Bedrock.\n",
    "\n",
    "To demonstrate the access control capabilities enabled by metadata filtering in Knowledge Bases, let's consider a use case where you work at a large enterprise, AcmeCorp. At AcmeCorp we want to create a Knowledge Base containing content from various s3 buckets.  However, each user does not have access to all data. A RAG architecture is perfect for this use case since we can restrict the retrieval to only the documents we have access to.  \n",
    "\n",
    "To complete this notebook you should have a role with access to the following services: Amazon S3, AWS STS, AWS Lambda, AWS CloudFormation, Amazon Bedrock, Amazon Cognito and Amazon Opensearch Serverless. \n",
    "\n",
    "This notebook contains the following sections:\n",
    "\n",
    "0. **Base Infrastructure Deployment**: In this section you will deploy an Amazon Cloudformation Template which will create and configure some of the services used for the solution. \n",
    "1. **Amazon Cognito:** You are going to populate an Amazon Cognito pool with three users. We will use the unique identifiers generated by Cognito for each user to associate document corpus with the respective users.\n",
    "2. **User-corpus association in Amazon DynamoDB:** You will populate an Amazon DynamoDB table which will store user-corpus associations. \n",
    "3. **Dataset download:** For this notebook you will use documents provided in an s3 bucket and stored in 3 different folders.\n",
    "4. **Metadata association:** You will use the user identifiers generated by Cognito to create metadata files associated to each corpus.\n",
    "5. **Create a Knowledge Base for Amazon Bedrock**: You will create and sync the Knowledge Base with the documents and associated metadata.\n",
    "6. **Update AWS Lambda:** Until Boto3/Lambda is updated -- Create a Lambda Layer to include the latest SDK.\n",
    "7. **Create and run a Streamlit Application:** You will create a simple interface to showcase access control with metadata filtering using a Streamlit application\n",
    "8. **Clean up:** Delete all the resources created during this notebook to avoid unnecessary costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6691e2-8111-4cec-b9f9-64ab8073a91c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.9 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "langchain-aws 0.1.6 requires boto3<1.35.0,>=1.34.51, but you have boto3 1.35.9 which is incompatible.\n",
      "sagemaker-jupyterlab-extension-common 0.1.18 requires pydantic==1.*, but you have pydantic 2.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU opensearch-py streamlit streamlit-cognito-auth retrying boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50d670-cfab-4e6d-9f6d-4d6022b9601d",
   "metadata": {},
   "source": [
    "Let's import necessary Python modules and libraries, and initialize AWS service clients required for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46908c28-2820-4858-ab58-ecbd91f98b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import requests\n",
    "import random\n",
    "from utilsmod import create_base_infrastructure, create_kb_infrastructure, updateDataAccessPolicy, createAOSSIndex, replace_vars\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "lambda_client = boto3.client('lambda')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "cloudformation = boto3.client('cloudformation')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock = boto3.client(\"bedrock\",region_name=region)\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "cognito_client = boto3.client('cognito-idp', region_name=region)\n",
    "identity_arn = session.client('sts').get_caller_identity()['Arn']\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e4bd3e-278b-4f71-8975-feee1fd820d1",
   "metadata": {},
   "source": [
    "### 0. Base Infrastructure Deployment \n",
    "We have created for you an Amazon CloudFormation template which will automatically set up some of the services needed for this notebook.\n",
    "\n",
    "This template will automatically create:\n",
    "- Amazon Cognito User Pool and App Client. (user_pool_id, cognito_arn, client_id, client_secret)\n",
    "- Amazon DynamoDB Table\n",
    "- Amazon S3 Bucket\n",
    "- AWS Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4601853-bce6-4cfd-9481-aae85126112b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca0902c-4861-4ca2-895d-6eb8617882bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating stack KB-E2E-Base-kbse1d68b57 (arn:aws:cloudformation:us-west-2:431615879134:stack/KB-E2E-Base-kbse1d68b57/e1409800-6648-11ef-8162-02dad0048ad3)\n",
      "Stack outputs:\n",
      "User Pool ID: us-west-2_zidUml6yG\n",
      "User Pool ARN: arn:aws:cognito-idp:us-west-2:431615879134:userpool/us-west-2_zidUml6yG\n",
      "Cognito ARN: arn:aws:cognito-idp:us-west-2:431615879134:userpool/us-west-2_zidUml6yG\n",
      "Client ID: 4l78s47crsfjiq7dsvl6m5ghvg\n",
      "Client Secret: 1u8jcu923foi8rbvvjilbe4li1l36827buoojid9ota6uuc98485\n",
      "DynamoDB Table: kbse1d68b57_user_corpus_list_association\n",
      "S3 Bucket: kbse1d68b57-bucket\n",
      "Lambda Arn: arn:aws:lambda:us-west-2:431615879134:function:kbse1d68b57-lambda-function\n",
      "OpenSearchCollectionId: obdbwdsvnyky5elupqck\n"
     ]
    }
   ],
   "source": [
    "def short_uuid():\n",
    "    uuid_str = str(uuid.uuid4())\n",
    "    return uuid_str[:8]\n",
    "\n",
    "solution_id = 'KBS{}'.format(short_uuid()).lower()\n",
    "user_pool_id, user_pool_arn, cognito_arn, client_id, client_secret, dynamo_table, s3_bucket, lambda_function_arn, collection_id = create_base_infrastructure(solution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee15a8f-0c65-4a21-b693-6715927af38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'user_pool_id' (str)\n",
      "Stored 'user_pool_arn' (str)\n",
      "Stored 'cognito_arn' (str)\n",
      "Stored 'client_id' (str)\n",
      "Stored 'client_secret' (str)\n",
      "Stored 'dynamo_table' (str)\n",
      "Stored 's3_bucket' (str)\n",
      "Stored 'lambda_function_arn' (str)\n",
      "Stored 'collection_id' (str)\n",
      "Stored 'solution_id' (str)\n"
     ]
    }
   ],
   "source": [
    "%store user_pool_id user_pool_arn cognito_arn client_id client_secret dynamo_table s3_bucket lambda_function_arn collection_id solution_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b10002-eba7-4255-aa27-a8bd797b750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "client_id                       -> '4l78s47crsfjiq7dsvl6m5ghvg'\n",
      "client_secret                   -> '1u8jcu923foi8rbvvjilbe4li1l36827buoojid9ota6uuc98\n",
      "cognito_arn                     -> 'arn:aws:cognito-idp:us-west-2:431615879134:userpo\n",
      "collection_id                   -> 'obdbwdsvnyky5elupqck'\n",
      "corpus_ids                      -> ['fa1c3635-fc7e-4249-91da-d828a20f83bc', '6394b9f6\n",
      "datasource_id                   -> '5LCFZHJZRJ'\n",
      "dynamo_table                    -> 'kbse1d68b57_user_corpus_list_association'\n",
      "indexName                       -> 'kb-acl-index-kbs27be3efe'\n",
      "kb_id                           -> '5GFND4H4X4'\n",
      "lambda_function_arn             -> 'arn:aws:lambda:us-west-2:431615879134:function:kb\n",
      "s3_bucket                       -> 'kbse1d68b57-bucket'\n",
      "solution_id                     -> 'kbse1d68b57'\n",
      "user_ids                        -> ['58f1e390-8071-705e-f71b-7406907b1d56', '08b1b3e0\n",
      "user_pool_arn                   -> 'arn:aws:cognito-idp:us-west-2:431615879134:userpo\n",
      "user_pool_id                    -> 'us-west-2_zidUml6yG'\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dadd1f0-13e8-4630-beae-5a401b5bafc2",
   "metadata": {},
   "source": [
    "### 1. Amazon Cognito User Pool: Users and Corpus\n",
    "#### Create users and corpus into the user pool\n",
    "We will create users and corpus to test out the use case. User ids are stored for later use when retrieving information.\n",
    "For the notebook to work you will need to replace the placeholder for 2 doctors and 3 patients. This users will be created in the Amazon Cognito user pool and you will later need them to log into the web application. While this is a dummy user creation for test purposes, in production use cases you will need to follow you organization best practices and guidelines to create users. \n",
    "\n",
    "**For this example, the first doctor will have associated the first two patients, and the second doctor will have associated the third patient.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f034bcd-44a7-463d-981f-c3b94a754c71",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> \n",
    "<br><b>Password minimum length:</b>8 character(s)\n",
    "<br><b>Password requirements</b>\n",
    "<br>Contains at least 1 number\n",
    "<br>Contains at least 1 special character\n",
    "<br>Contains at least 1 uppercase letter\n",
    "<br>Contains at least 1 lowercase letter\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e20cb84-f7c0-4d9d-b7b8-6639ed1f5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "    {\n",
    "        'name': 'Highway Harry',\n",
    "        'email': 'highway.harry@acmecorp.com',\n",
    "        'password': 'Highway.Harry.123$',\n",
    "        'corpus': ['highway']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Wildlife Walter',\n",
    "        'email': 'wildlife.walter@acmecorp.com',\n",
    "        'password': 'Wildlife.Walter.123$',\n",
    "        'corpus': ['wildlife']\n",
    "    },\n",
    "    {\n",
    "        'name': 'Admin Amy',\n",
    "        'email': 'admin.amy@acmecorp.com',\n",
    "        'password': 'Admin.Amy.123$',\n",
    "        'corpus': ['highway', 'wildlife']\n",
    "    },\n",
    "]\n",
    "\n",
    "corpus = [\n",
    "    {\n",
    "        'name': 'highway',\n",
    "        'description': 'document regarding highway and roadsign regulations',\n",
    "        's3path': f\"s3://{s3_bucket}/highway/\"\n",
    "    },\n",
    "    {\n",
    "        'name': 'wildlife',\n",
    "        'description': 'documents regarding fishing and hunting regulations',\n",
    "        's3path': f's3://{s3_bucket}/wildlife/'\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad117c96-f3e5-4024-8431-6936ff899112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User created: highway.harry@acmecorp.com\n",
      "User id: f801f330-1031-7092-9be5-1ae68bb86d28\n",
      "User created: wildlife.walter@acmecorp.com\n",
      "User id: b8811320-9011-7085-6116-3918c3844836\n",
      "User created: admin.amy@acmecorp.com\n",
      "User id: d8d193a0-b051-7025-4c2e-901e68575ab1\n",
      "User IDs: ['f801f330-1031-7092-9be5-1ae68bb86d28', 'b8811320-9011-7085-6116-3918c3844836', 'd8d193a0-b051-7025-4c2e-901e68575ab1']\n",
      "Corpus IDs: ['12ce2ffe-16bc-4de0-8ee0-a8e527a97729', '2a0b6654-2ac9-4fd2-b782-f8f190ecb3d4']\n",
      "Stored 'user_ids' (list)\n",
      "Stored 'corpus_ids' (list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_ids = []\n",
    "corpus_ids = []\n",
    "\n",
    "def create_user(user_data, user_type):\n",
    "    user_ids = []\n",
    "    for user in user_data:\n",
    "        response = cognito_client.admin_create_user(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            UserAttributes=[\n",
    "                {'Name': 'name', 'Value': user['name']},\n",
    "                {'Name': 'email', 'Value': user['email']},\n",
    "                {'Name': 'email_verified', 'Value': 'true'}\n",
    "            ],\n",
    "            ForceAliasCreation=False,\n",
    "            MessageAction='SUPPRESS'\n",
    "        )\n",
    "        cognito_client.admin_set_user_password(\n",
    "            UserPoolId=user_pool_id,\n",
    "            Username=user['email'],\n",
    "            Password=user['password'],\n",
    "            Permanent=True\n",
    "        )\n",
    "        print(f\"{user_type.capitalize()} created:\", response['User']['Username'])\n",
    "        print(f\"{user_type.capitalize()} id:\", response['User']['Attributes'][3]['Value'])\n",
    "        user_ids.append(response['User']['Attributes'][3]['Value'])\n",
    "    return user_ids\n",
    "\n",
    "user_ids = create_user(users, 'user')\n",
    "corpus_ids = [str(uuid.uuid4()) for c in corpus]\n",
    "\n",
    "print(\"User IDs:\", user_ids)\n",
    "print(\"Corpus IDs:\", corpus_ids)\n",
    "\n",
    "%store user_ids corpus_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a460e9-acce-4a4e-89a3-739270e7a594",
   "metadata": {},
   "source": [
    "### 2. User-corpus association in DynamoDB\n",
    "In this section we will populate the already created DynamoDB table with the user-corpus associations. This will be useful later on to retrieve the list of corpus ids a user is allowed to filter by. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77aeda75-50dc-4492-b7b1-4547848f0c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "table = dynamodb_resource.Table(dynamo_table)\n",
    "corpus_mapping = [entry['name'] for entry in corpus]\n",
    "with table.batch_writer() as batch:\n",
    "    for j,users in enumerate(users):\n",
    "        temp = []\n",
    "        for i,c in enumerate(corpus_mapping):\n",
    "            if c in users['corpus']:\n",
    "                temp.append(corpus_ids[i])\n",
    "\n",
    "        batch.put_item(\n",
    "            Item={\n",
    "                'user_id': user_ids[j],\n",
    "                'corpus_id_list': temp\n",
    "            }\n",
    "        )\n",
    "\n",
    "print('Data inserted successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6174a7a0-d1a9-4d09-8e55-c577f5a17471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: source_transcripts/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf to s3://kbse1d68b57-bucket/highway/23 CFR Part 655 (up to date as of 8-21-2024).pdf\n",
      "upload: source_transcripts/wildlife/Loon - Wikipedia.pdf to s3://kbse1d68b57-bucket/wildlife/Loon - Wikipedia.pdf\n",
      "upload: source_transcripts/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf to s3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./source_transcripts/ s3://{s3_bucket}/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59b41e1-61cf-46bc-9285-b21811da2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the corpus and their corresponding IDs\n",
    "for i, corpus_entry in enumerate(corpus):\n",
    "    corpus_id = corpus_ids[i]\n",
    "    s3path = corpus_entry['s3path']\n",
    "    \n",
    "    # Get bucket and prefix\n",
    "    # Remove 's3://' and split bucket and prefix\n",
    "    path_parts = s3path.replace('s3://', '').split('/', 1)\n",
    "    bucket = path_parts[0]\n",
    "    prefix = path_parts[1] if len(path_parts) > 1 else ''\n",
    "    \n",
    "    # List all files in the S3 folder\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        files = [obj['Key'] for obj in response['Contents'] if obj['Key'] != prefix]\n",
    "    else:\n",
    "        files = []\n",
    "    \n",
    "    for file in files:\n",
    "        metadata = {\n",
    "            \"metadataAttributes\": {\n",
    "                \"corpus_id\": corpus_id\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload metadata file to S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket,\n",
    "            Key=f\"{file}.metadata.json\",\n",
    "            Body=json.dumps(metadata, indent=4),\n",
    "            ContentType='application/json'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833962b8-c0c3-4fc3-af4a-9eee572c1f22",
   "metadata": {},
   "source": [
    "### 5. Upload to Amazon S3\n",
    "Knowledge Bases for Amazon Bedrock, currently require data to reside in an Amazon S3 bucket. We will upload both files and metadata files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdeafa-15b5-4a12-88e7-d234fb80eb6f",
   "metadata": {},
   "source": [
    "### 6. Create a Knowledge Base for Amazon Bedrock\n",
    "\n",
    "In this section we will go through all the steps to create and test a Knowledge Base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2697404a-685c-4ecc-9554-ef68b4ada7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index name: kb-acl-index-kbse1d68b57\n",
      "Stored 'indexName' (str)\n"
     ]
    }
   ],
   "source": [
    "indexName = \"kb-acl-index-\" + solution_id\n",
    "print(\"Index name:\",indexName)\n",
    "%store indexName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59083c04-1efa-430b-ad86-6137dc092c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accessPolicyDetail': {'createdDate': 1724964874088, 'description': 'dataAccessPolicy', 'lastModifiedDate': 1724964931661, 'name': 'kbse1d68b57-kbcollection-access', 'policy': [{'Rules': [{'Resource': ['collection/kbse1d68b57-kbcollection'], 'Permission': ['aoss:CreateCollectionItems', 'aoss:UpdateCollectionItems', 'aoss:DescribeCollectionItems'], 'ResourceType': 'collection'}, {'Resource': ['index/kbse1d68b57-kbcollection/*'], 'Permission': ['aoss:CreateIndex', 'aoss:DescribeIndex', 'aoss:ReadDocument', 'aoss:WriteDocument', 'aoss:UpdateIndex', 'aoss:DeleteIndex'], 'ResourceType': 'index'}], 'Principal': ['arn:aws:iam::431615879134:role/kbse1d68b57-kbrole', 'arn:aws:sts::431615879134:assumed-role/namer-summit-2024/SageMaker']}], 'policyVersion': 'MTcyNDk2NDkzMTY2MV8y', 'type': 'data'}, 'ResponseMetadata': {'RequestId': '54a2a811-5539-44da-a838-bd743c3bcc6f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '54a2a811-5539-44da-a838-bd743c3bcc6f', 'date': 'Thu, 29 Aug 2024 20:55:31 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '762', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'kb-acl-index-kbse1d68b57'}\n"
     ]
    }
   ],
   "source": [
    "updateDataAccessPolicy(solution_id) # Adding the current role to the collection's data access policy\n",
    "time.sleep(60) # Changes to the data access policy might take a bit to update\n",
    "createAOSSIndex(indexName, region, collection_id) # Create the AOSS index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83730d6-d98f-4a7d-a493-dfb5202053bd",
   "metadata": {},
   "source": [
    "#### Create the Knowledge Base\n",
    "In this section you will create the Knowledge Base. Before creating a new KB we need to define which embeddings model we want it to use. In this case we will be using Amazon Titan Embeddings V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a1ea0-4b2c-4803-82f7-d985d2e93b3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Amazon Titan Embeddings V2 access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98325514-bad0-477b-8003-0972a4608dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddingModelArn = \"arn:aws:bedrock:{}::foundation-model/amazon.titan-embed-text-v2:0\".format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982e0b9-76bb-4569-a677-89ecee25d88d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can create our Knowledge Base for Amazon Bedrock. We have created an Amazon CloudFormation template which takes care of the configuration needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104e285-e051-45fb-b04c-6281f10b4bb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The deployment of the Amazon Cloudformation template should take around <b>1-2 minutes</b>.\n",
    "    \n",
    "You can also follow the deployment status in the Amazon Cloudformation console. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80516aa-84c7-45d1-a3a0-5f86d6c76aed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack creation initiated: arn:aws:cloudformation:us-west-2:431615879134:stack/KB-E2E-KB-kbse1d68b57/2ba11f00-6649-11ef-ac3a-06b5122181c5\n",
      "KBID: ELSQWLXZWS\n",
      "DS: ELSQWLXZWS|ERK6UW1AKX\n"
     ]
    }
   ],
   "source": [
    "kb_id, datasource_id = create_kb_infrastructure(solution_id, s3_bucket, embeddingModelArn, indexName, region, account_id, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6309cab0-3e54-4fa1-a184-ee95ea4f8a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'kb_id' (str)\n",
      "Stored 'datasource_id' (str)\n"
     ]
    }
   ],
   "source": [
    "%store kb_id datasource_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8405b118-c4f1-4abc-9faf-043b5615ec39",
   "metadata": {},
   "source": [
    "#### Sync the Knowledge Base\n",
    "As we have created and associated the data source to the Knowledge Base, we can proceed to Sync the data. \n",
    "\n",
    "\n",
    "Each time you add, modify, or remove files from the S3 bucket for a data source, you must sync the data source so that it is re-indexed to the knowledge base. Syncing is incremental, so Amazon Bedrock only processes the objects in your S3 bucket that have been added, modified, or deleted since the last sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b95bcf2e-241e-48d3-b914-70c73cdb7be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingestion_job_response = bedrock_agent_client.start_ingestion_job(\n",
    "    knowledgeBaseId=kb_id,\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial Ingestion'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21c68a8a-f696-476a-baf8-2e5fe124cab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n",
      "STARTING\n",
      "COMPLETE\n",
      "Waiting for changes to take place in the vector database\n"
     ]
    }
   ],
   "source": [
    "status = bedrock_agent_client.get_ingestion_job(\n",
    "    knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "    dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "    ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    ")[\"ingestionJob\"][\"status\"]\n",
    "print(status)\n",
    "while status not in [\"COMPLETE\", \"FAILED\", \"STOPPED\"]:\n",
    "    status = bedrock_agent_client.get_ingestion_job(\n",
    "        knowledgeBaseId=ingestion_job_response[\"ingestionJob\"][\"knowledgeBaseId\"],\n",
    "        dataSourceId=ingestion_job_response[\"ingestionJob\"][\"dataSourceId\"],\n",
    "        ingestionJobId=ingestion_job_response[\"ingestionJob\"][\"ingestionJobId\"]\n",
    "    )[\"ingestionJob\"][\"status\"]\n",
    "    print(status)\n",
    "    time.sleep(30)\n",
    "print(\"Waiting for changes to take place in the vector database\")\n",
    "time.sleep(30) # Wait for all changes to take place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed01aff-93ba-49cf-99cf-260c3a6d1117",
   "metadata": {},
   "source": [
    "#### Test the Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the **retrieve** and **retrieve_and_generate** APIs.\n",
    "\n",
    "Let's examine a test case with patient 0's transcript, where they mention a cat named Kelly. We'll query the knowledge base using the metadata filter for patient 0 to retrieve information about Kelly. Changing the patient_id will prevent the model from responding accurately. Read through the PDFs for other questions you might want to ask. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005a770-86f9-4d20-946d-cd93c29d3e9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this first example we are going to use the **retrieve and generate API**. This API queries a knowledge base and generates responses based on the retrieved results, using an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d67a17-330d-42d2-98b0-4133378b7b6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Make sure you have enabled Anthropic Claude 3 Sonnet access in the Amazon Bedrock Console (model access). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9004e57-402f-4f7d-9834-bfffbcbfe336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To obtain permits for golden eagle activities such as scientific collecting, exhibition, religious use, depredation, nest take, and incidental take, you should submit your application to the \"Migratory Bird Permit Program Office\" in the region where you reside. The addresses for the regional offices can be found at 50 CFR 2.2 or on the U.S. Fish and Wildlife Service website.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieve and generate API\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"Which office do I submit for golden eagle permits?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\".format(region),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5,\n",
    "                    \"filter\": {\n",
    "                        \"equals\": {\n",
    "                            \"key\": \"corpus_id\",\n",
    "                            \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9540a5-9ea3-4563-9187-2287d4b9282f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this second example we are going to use the **retrieve API**. This API queries the knowledge base and retrieves relavant information from it, it does not generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3078a3a-7558-4bc9-a9bc-2a205c52b18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:  Endangered Species Act permit applications for the import or export of native endangered and threatened species may be obtained from the Division of Management Authority in accordance with paragraph (b)(3) of this section.   (5) You may obtain applications for bald and golden eagle permits (50 CFR part 22) and migratory bird permits (50 CFR part 21), except for banding and marking permits, from, and you may submit completed applications to, the “Migratory Bird Permit Program Office” in the Region in which you reside. For addresses of the regional offices, see 50 CFR 2.2, or go to: http://www.fws.gov/ migratorybirds/mbpermits/Addresses.html.   (c) Time notice. The Service will process all applications as quickly as possible. However, we cannot guarantee final action within the time limit you request. You should ensure that applications for permits for marine mammals and/or endangered and threatened species are postmarked at least 90 calendar days prior to the requested effective date. The time we require for processing of endangered and threatened species incidental take permits will vary according to the project scope and significance of effects. Submit applications for all other permits to the issuing/reviewing office and ensure they are postmarked at least 60 calendar days prior to the requested effective date.\n",
      "\n",
      "Chunk 1 Location:  {'s3Location': {'uri': 's3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf'}, 'type': 'S3'}\n",
      "\n",
      "Chunk 1 Score:  1.605639\n",
      "\n",
      "Chunk 1 Metadata:  {'x-amz-bedrock-kb-source-uri': 's3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AvSvun5EBGCZ5LoE_SU6L', 'corpus_id': '2a0b6654-2ac9-4fd2-b782-f8f190ecb3d4', 'x-amz-bedrock-kb-data-source-id': 'ERK6UW1AKX'}\n",
      "\n",
      "Chunk 2:  Migratory Bird Rehabilitation   50 CFR part 21   50   Migratory Bird Depredation   50 CFR part 21   100 50   Migratory Bird Depredation/ Homeowner   50 CFR part 21   50   BALD AND GOLDEN EAGLE PROTECTION ACT   Eagle Scientific Collecting   50 CFR part 22   100   Eagle Exhibition 50 CFR part 22   75   Eagle—Native American Religious Purposes   50 CFR part 22   No fee   Eagle Depredation Permit   50 CFR part 22   100   Golden Eagle Nest Take 50 CFR part 22   100 50.   Eagle Transport—Scientific or Exhibition   50 CFR part 22   75   Eagle Transport—Native American Religious Purposes   50 CFR part 22   No fee   General Eagle Permit—Disturbance Take   50 CFR part 22   100   Specific Eagle Permit—Disturbance Take   50 CFR part 22   Commercial—2,500; Noncommercial—500   Commercial—500; Noncommercial—150.   General Eagle Permit—Nest Take   50 CFR part 22   100   Specific Eagle Permit—Nest Take (Single nest)   50 CFR part 22   Commercial—2,500; Noncommercial—500   Commercial—500; Noncommercial—150.   Specific\n",
      "\n",
      "Chunk 2 Location:  {'s3Location': {'uri': 's3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf'}, 'type': 'S3'}\n",
      "\n",
      "Chunk 2 Score:  1.5440619\n",
      "\n",
      "Chunk 2 Metadata:  {'x-amz-bedrock-kb-source-uri': 's3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AxSvun5EBGCZ5LoE_SU6L', 'corpus_id': '2a0b6654-2ac9-4fd2-b782-f8f190ecb3d4', 'x-amz-bedrock-kb-data-source-id': 'ERK6UW1AKX'}\n",
      "\n",
      "Chunk 3:  Import and export 21.67   Banding or marking 21.70   Scientific collecting 21.73   Rehabilitation 21.76   Falconry 21.82   Raptor propagation permit 21.85   Waterfowl sale and disposal 21.88   Special purpose 21.95   Depredation 21.100   Special Canada goose 21.120   Special double-crested cormorant 21.123   Eagle permits:   Scientific or exhibition 22.50.   Indian religious use 22.60.   Falconry purposes 22.70.   Depredation and protection of health and safety 22.100.   Permits for incidental take of eagles 22.200 or 22.210.   Permits for incidental take of eagles by power lines 22.200 or 22.210.   Permits for disturbance take of eagles 22.200 or 22.210.   Permits for nest take of eagle 22.200 or 22.210.   Permits for golden eagle nest take for resource recovery operations 22.325.   Permits for bald eagle take exempted under the Endangered Species Act 22.400.   [39 FR 1161, Jan. 4, 1974, as amended at 42 FR 10465, Feb. 22, 1977; 42 FR 32377, June\n",
      "\n",
      "Chunk 3 Location:  {'s3Location': {'uri': 's3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf'}, 'type': 'S3'}\n",
      "\n",
      "Chunk 3 Score:  1.5380808\n",
      "\n",
      "Chunk 3 Metadata:  {'x-amz-bedrock-kb-source-uri': 's3://kbse1d68b57-bucket/wildlife/50 CFR Part 13 (up to date as of 8-21-2024).pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3A4yvun5EBGCZ5LoE_SU6N', 'corpus_id': '2a0b6654-2ac9-4fd2-b782-f8f190ecb3d4', 'x-amz-bedrock-kb-data-source-id': 'ERK6UW1AKX'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":3,\n",
    "            \"filter\": {\n",
    "                 \"equals\": {\n",
    "                    \"key\": \"corpus_id\",\n",
    "                    \"value\": corpus_ids[1]\n",
    "                        }\n",
    "                    }\n",
    "                } \n",
    "            },\n",
    "    retrievalQuery={\n",
    "        'text': \"Which office do I submit for golden eagle permits?\"\n",
    "            \n",
    "        }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents\n",
    "# each list has content,location,score,metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d7ed4-b65c-4cde-8249-8ab6d7b09027",
   "metadata": {},
   "source": [
    "### 7. Add Lambda Layer\n",
    "At the time of developing this notebook, the latest Boto3 version available in Lambda with Python 3.12 does not include metadata filtering capabilities. To solve this, we will create and attach an AWS Lambda Layer with the latest Boto3 version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc087b17-a1d9-4c2b-8356-858385427d19",
   "metadata": {
    "tags": []
   },
   "source": [
    "For this section to run you will need the **zip** package to by installed at the system level.\n",
    "\n",
    "You can check if zip is installed running the following command: !zip\n",
    "\n",
    "If it is not installed you will need to install it using the appropriate package manager (apt-get for Debian-based systems or yum for RHEL-based systems for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de169586-ddf3-4a29-8cb7-9422b5f33dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we have the lambda layer already attached to the lambda function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e05da1-5561-421f-beb2-8b963bbd725c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "zip is already the newest version (3.0-12build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "#!zip\n",
    "!sudo apt-get install zip -y # Debian-based systems \n",
    "#!sudo yum install zip -y # RHEL-based systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a07a879f-37b3-46e4-97cc-6f422fcde310",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/namer-summit-2024-genAI-privacy/latest-sdk-layer\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.9 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "langchain-aws 0.1.6 requires boto3<1.35.0,>=1.34.51, but you have boto3 1.35.9 which is incompatible.\n",
      "sagemaker-jupyterlab-extension-common 0.1.18 requires pydantic==1.*, but you have pydantic 2.7.3 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m/home/sagemaker-user/namer-summit-2024-genAI-privacy\n"
     ]
    }
   ],
   "source": [
    "!mkdir latest-sdk-layer\n",
    "%cd latest-sdk-layer\n",
    "!pip install -qU boto3 botocore -t python/lib/python3.12/site-packages/\n",
    "!zip -rq latest-sdk-layer.zip .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "955e398b-5009-43c6-bd4e-df8b4f2ba55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes):\n",
    "    with open(zip_file_path, 'rb') as f:\n",
    "        response = lambda_client.publish_layer_version(\n",
    "            LayerName=layer_name,\n",
    "            Description=description,\n",
    "            Content={\n",
    "                'ZipFile': f.read(),\n",
    "            },\n",
    "            CompatibleRuntimes=compatible_runtimes\n",
    "        )\n",
    "    return response['LayerVersionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b420050-ffef-4905-b973-d4a524303f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_name = 'latest-sdk-layer'\n",
    "description = 'Layer with the latest boto3 version.'\n",
    "zip_file_path = 'latest-sdk-layer/latest-sdk-layer.zip'\n",
    "compatible_runtimes = ['python3.12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "349a66a3-e292-4d22-95bf-28e12491ed8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer version ARN: arn:aws:lambda:us-west-2:431615879134:layer:latest-sdk-layer:5\n"
     ]
    }
   ],
   "source": [
    "layer_version_arn = publish_lambda_layer(layer_name, description, zip_file_path, compatible_runtimes)\n",
    "print(\"Layer version ARN:\", layer_version_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3400953a-6dd9-4585-b0bf-8e49fcc1fa51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer added to the Lambda function successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Add the layer to the Lambda function\n",
    "    lambda_client.update_function_configuration(\n",
    "        FunctionName=lambda_function_arn,\n",
    "        Layers=[layer_version_arn]\n",
    "    )\n",
    "    print(\"Layer added to the Lambda function successfully.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    print(f\"Error adding layer to Lambda function: {e.response['Error']['Message']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988ef11-d814-43cc-be20-9f303535c3e9",
   "metadata": {},
   "source": [
    "### 8. Create Streamlit Application\n",
    "To showcase the interaction between doctors and the Knowledge Bases, we can develop a user-friendly web application using Streamlit for testing purposes, a popular open-source Python library for building interactive data apps. Streamlit provides a simple and intuitive way to create custom interfaces that can seamlessly integrate with the various AWS services involved in this solution.\n",
    "\n",
    "Here is the application, **don't modify the placeholders, we will replace them in the next cell.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d1c24a-354d-4272-8607-bd416471caac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import streamlit as st\n",
    "from streamlit_cognito_auth import CognitoAuthenticator\n",
    "\n",
    "pool_id = \"<<replace_pool_id>>\"\n",
    "app_client_id = \"<<replace_app_client_id>>\"\n",
    "app_client_secret = \"<<replace_app_client_secret>>\"\n",
    "kb_id = \"<<replace_kb_id>>\"\n",
    "lambda_function_arn = '<<replace_lambda_function_arn>>'\n",
    "dynamo_table = '<<replace_dynamo_table_name>>'\n",
    "\n",
    "authenticator = CognitoAuthenticator(\n",
    "    pool_id=pool_id,\n",
    "    app_client_id=app_client_id,\n",
    "    app_client_secret= app_client_secret,\n",
    "    use_cookies=False\n",
    ")\n",
    "\n",
    "is_logged_in = authenticator.login()\n",
    "\n",
    "if not is_logged_in:\n",
    "    st.stop()\n",
    "\n",
    "def logout():\n",
    "    authenticator.logout()\n",
    "\n",
    "def get_user_sub(user_pool_id, username):\n",
    "    cognito_client = boto3.client('cognito-idp')\n",
    "    try:\n",
    "        response = cognito_client.admin_get_user(\n",
    "            UserPoolId=pool_id,\n",
    "            Username=authenticator.get_username()\n",
    "        )\n",
    "        sub = None\n",
    "        for attr in response['UserAttributes']:\n",
    "            if attr['Name'] == 'sub':\n",
    "                sub = attr['Value']\n",
    "                break\n",
    "        return sub\n",
    "    except cognito_client.exceptions.UserNotFoundException:\n",
    "        print(\"User not found.\")\n",
    "        return None\n",
    "\n",
    "def get_corpus_ids(user_id):\n",
    "    dynamodb = boto3.client('dynamodb')\n",
    "    response = dynamodb.query(\n",
    "        TableName=dynamo_table,\n",
    "        KeyConditionExpression='user_id = :user_id',\n",
    "        ExpressionAttributeValues={\n",
    "            ':user_id': {'S': user_id}\n",
    "        }\n",
    "    )\n",
    "    print(response)\n",
    "    corpus_id_list = []  # Initialize the list\n",
    "    for item in response['Items']:\n",
    "        corpus_ids = item.get('corpus_id_list', {}).get('L', [])\n",
    "        corpus_id_list.extend([corpus_id['S'] for corpus_id in corpus_ids])\n",
    "    return corpus_id_list\n",
    "\n",
    "def search_transcript(user_id, kb_id, text, corpus_ids):\n",
    "    # Initialize the Lambda client\n",
    "    lambda_client = boto3.client('lambda')\n",
    "\n",
    "    # Payload for the Lambda function\n",
    "    payload = json.dumps({\n",
    "        \"userId\": sub,\n",
    "        \"knowledgeBaseId\": kb_id,\n",
    "        \"text\": text, \n",
    "        \"corpusIds\": corpus_ids\n",
    "    }).encode('utf-8')\n",
    "\n",
    "    try:\n",
    "        # Invoke the Lambda function\n",
    "        response = lambda_client.invoke(\n",
    "            FunctionName=lambda_function_arn,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=payload\n",
    "        )\n",
    "\n",
    "        # Process the response\n",
    "        if response['StatusCode'] == 200:\n",
    "            response_payload = json.loads(response['Payload'].read().decode('utf-8'))\n",
    "            return response_payload\n",
    "        else:\n",
    "            # Handle error response\n",
    "            return {'error': 'Failed to fetch data'}\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exception\n",
    "        return {'error': str(e)}\n",
    "\n",
    "sub = get_user_sub(pool_id, authenticator.get_username())\n",
    "print(sub)\n",
    "corpus_ids = get_corpus_ids(sub)\n",
    "print(corpus_ids)\n",
    "\n",
    "# Application Front\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"User Information\")\n",
    "    st.markdown(\"## User\")\n",
    "    st.text(authenticator.get_username())\n",
    "    st.markdown(\"## User Id\")\n",
    "    st.text(sub)\n",
    "    # selected_patient = st.selectbox(\"Select a patient (or 'All' for all patients)\", ['All'] + patient_ids)\n",
    "    st.button(\"Logout\", \"logout_btn\", on_click=logout)\n",
    "\n",
    "st.header(\"Corpus Search Tool\")\n",
    "\n",
    "# Text input for the search query\n",
    "query = st.text_input(\"Enter your search query:\")\n",
    "\n",
    "if st.button(\"Search\"):\n",
    "    if query:\n",
    "        # Perform search\n",
    "        corpus_ids_filter = corpus_ids\n",
    "        results = search_transcript(sub, kb_id, query, corpus_ids_filter)\n",
    "        print(results)\n",
    "        if results:\n",
    "            st.subheader(\"Search Results:\")\n",
    "            st.markdown(results[\"body\"], unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(\"No matching results found in corpus.\")\n",
    "    else:\n",
    "        st.write(\"Please enter a search query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df2616f0-0eb8-4336-a967-7ad3c07bc429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_vars(\"app.py\", user_pool_id, client_id, client_secret, kb_id, lambda_function_arn, dynamo_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e42cb6-bb35-4f3f-98ff-ad8ae8fae597",
   "metadata": {},
   "source": [
    "#### Execute the streamlit locally\n",
    "Execute the cell below to run the Streamlit application.\n",
    "\n",
    "**Use the email and password of the doctors you defined at the top of the notebook to access the application.**\n",
    "\n",
    "Once you have logged in, you can filter by specific patients you have assigned (dropdown in the left panel), or all to query the knowledge base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79ef8ed1-5240-4453-bc71-b2b0cffb453e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://169.255.255.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.213.171.250:8501\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b54a555-4f4f-4086-9a08-20798a17e618",
   "metadata": {},
   "source": [
    "If you are executing this notebook on SageMaker Studio you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<STUDIOID>>.studio.<<REGION>>.sagemaker.aws/jupyterlab/default/proxy/8501/\n",
    "```\n",
    "\n",
    "If you are executing this notebook on a SageMaker Notebook you can access the Streamlit application in the following url. \n",
    "\n",
    "```\n",
    "https://<<NOTEBOOKID>>.notebook.<<REGION>>.sagemaker.aws/proxy/8501/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a024bd0a-90c8-446e-961c-7fc7dcb92b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://rxhmevhu84g12we.studio.us-west-2.sagemaker.aws/jupyterlab/default/proxy/8501/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4a706-8c02-48ed-bb35-0fac763db663",
   "metadata": {},
   "source": [
    "### 9. Clean up\n",
    "**Before running this cell you will need to stop the cell above where the app is runnning!**\n",
    "\n",
    "Run the following cell to delete the created resources and avoid unnecesary costs. This should take about 2-3 minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f96931b-aa6b-4e81-824e-bfce6c59016e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All objects in kbse1d68b57-bucket have been deleted.\n",
      "Deleting stack: KB-E2E-KB-kbse1d68b57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Wait for the stack deletion to complete\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m cloudformation\u001b[38;5;241m.\u001b[39mget_waiter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstack_delete_complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStackName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStack \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstack_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m deleted successfully.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:55\u001b[0m, in \u001b[0;36mcreate_waiter_with_client.<locals>.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[43mWaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/waiter.py:392\u001b[0m, in \u001b[0;36mWaiter.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m         reason \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax attempts exceeded. Previously accepted state: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macceptor\u001b[38;5;241m.\u001b[39mexplanation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    386\u001b[0m         )\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaiterError(\n\u001b[1;32m    388\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    389\u001b[0m         reason\u001b[38;5;241m=\u001b[39mreason,\n\u001b[1;32m    390\u001b[0m         last_response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    391\u001b[0m     )\n\u001b[0;32m--> 392\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_amount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Delete all objects in the bucket\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=s3_bucket)\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            s3_client.delete_object(Bucket=s3_bucket, Key=obj['Key'])\n",
    "        print(f\"All objects in {s3_bucket} have been deleted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting objects from {s3_bucket}: {e}\")\n",
    "\n",
    "# Define the stack names to delete\n",
    "stack_names = [\"KB-E2E-KB-{}\".format(solution_id),\"KB-E2E-Base-{}\".format(solution_id)]\n",
    "\n",
    "# Iterate over the stack names and delete each stack\n",
    "for stack_name in stack_names:\n",
    "    try:\n",
    "        # Retrieve the stack information\n",
    "        stack_info = cloudformation.describe_stacks(StackName=stack_name)\n",
    "        stack_status = stack_info['Stacks'][0]['StackStatus']\n",
    "\n",
    "        # Check if the stack exists and is in a deletable state\n",
    "        if stack_status != 'DELETE_COMPLETE':\n",
    "            # Delete the stack\n",
    "            cloudformation.delete_stack(StackName=stack_name)\n",
    "            print(f'Deleting stack: {stack_name}')\n",
    "\n",
    "            # Wait for the stack deletion to complete\n",
    "            waiter = cloudformation.get_waiter('stack_delete_complete')\n",
    "            waiter.wait(StackName=stack_name)\n",
    "            print(f'Stack {stack_name} deleted successfully.')\n",
    "        else:\n",
    "            print(f'Stack {stack_name} does not exist or has already been deleted.')\n",
    "\n",
    "    except cloudformation.exceptions.ClientError as e:\n",
    "        print(f'Error deleting stack {stack_name}: {e.response[\"Error\"][\"Message\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
